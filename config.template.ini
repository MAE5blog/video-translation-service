# 配置文件
# 复制此文件为 config.ini 并填入你的配置

[API]
# DeepSeek API密钥（可选，用于翻译润色）
# 访问 https://platform.deepseek.com 获取
deepseek_api_key = 

[Service]
# 翻译服务配置
host = 127.0.0.1
port = 50515

# 是否启动时预加载模型（false=预加载；true=按需通过 /models/load 加载）
lazy_load_models = false

# 是否由 batch_translate.py 按需加载/卸载服务端模型（适合显存紧张环境，如 Colab T4）
manage_models = false

# 是否在 ASR/翻译完成后卸载模型释放显存（会降低连续处理速度）
unload_models_after_tasks = false

[Models]
# ASR模型大小: tiny, base, small, medium, large-v3, reazonspeech
# reazonspeech 为日语优化模型（transformers 后端）；如需自定义，可用 reazonspeech:HF模型名
asr_model_size = reazonspeech

# 翻译模型:
#   facebook/nllb-200-1.3B (最高质量，较慢)
#   facebook/nllb-200-distilled-1.3B (质量接近，更快/更省资源)
#   facebook/nllb-200-distilled-600M (更快)
#   facebook/m2m100_418M (最快)
translation_model = facebook/nllb-200-1.3B

# 是否使用GPU
use_gpu = true

# beam_size (1-5，越大质量越好但越慢)
beam_size = 3

[GPU]
# 是否在 GPU 重任务前清理 CUDA 显存缓存（torch.cuda.empty_cache）
# 可降低 OOM 概率，但会略慢一些
clear_cuda_cache_before_tasks = false

[ASR]
# 指定音频语言（可提升嘈杂场景的识别稳定性；填错会变差）
# 备选示例：auto / en / zh / ja / ko / de / fr / es / ru / ar
language = auto

# ASR 分块识别（可显示进度条，也可降低长音频导致的 500/OOM 概率）
# 0=禁用；建议从 900（15分钟）起步，不稳定再降到 600/300
chunk_sec = 0

# 分块重叠秒数（避免切在单词中间；会产生少量重复，程序会尽量去重）
chunk_overlap_sec = 1.0

# Transformers ASR 内部分块（仅对 reazonspeech / transformers 后端生效）
# 默认 30s/5s 可显著降低长音频 OOM/掉线风险；如稳定可调大或设 0 禁用
transformers_chunk_sec = 30
transformers_stride_sec = 5.0

[Translation]
# 默认目标语言
default_target_language = zh

# 是否使用DeepSeek润色
use_deepseek_polish = false

[Subtitles]
# 字幕格式：srt / ass
# ass 支持样式/更清晰；若要“软字幕内封ass”，推荐用 MKV 容器（脚本会自动处理）
format = srt

# 修复字幕“滞留”：当 ASR 的 end 时间异常过长（常见于长静音/场景切换）时，按可读时长自动收缩 end，
# 避免一句话结束后字幕一直显示到下一句出现。
fix_linger = true

# 估算阅读参数（可按个人习惯调整）
min_duration_sec = 1.2
max_duration_sec = 20.0
chars_per_sec = 5.0
linger_slack_sec = 0.8

# 更保守的“滞留判断”：只有当某段时长明显异常（> 可读时长的多倍）才收缩，避免字幕提前结束
linger_trigger_sec = 6.0
linger_trigger_ratio = 6.0
linger_keep_ratio = 4.0

[Audio]
# 是否启用人声分离（Demucs，可改善背景音乐/嘈杂场景的识别）
# 需要额外安装：pip install demucs
enable_vocal_separation = false

# Demucs 模型名（常用：htdemucs / htdemucs_ft / mdx_extra）
vocal_separation_model = htdemucs

# 人声分离设备：auto / cpu / cuda
# 建议：若服务端模型占用显存较多导致 OOM，可设为 cpu；否则可用 auto/cuda 加速
vocal_separation_device = auto

# Demucs 分段秒数（仅对超长/超大音频触发；默认 1800=30分钟）
# 分段越大越不容易产生边界接缝，但越吃内存；如仍 OOM 可降到 600/300
vocal_separation_chunk_sec = 1800

# 说明：超长音频会自动分段运行 Demucs，避免一次性加载导致 CPU 内存 OOM（exit code=-9）
