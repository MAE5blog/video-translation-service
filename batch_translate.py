#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ‰¹é‡è§†é¢‘ç¿»è¯‘å·¥å…· v3.1
æ”¯æŒï¼šä¸Šä¸‹æ–‡ç¿»è¯‘ã€å¹¶å‘DeepSeekæ¶¦è‰²ã€æ–­ç‚¹ç»­ä¼ ã€æ—¥å¿—è®°å½•
"""

import os
import sys
import time
import json
import argparse
import logging
import threading
import tempfile
import re
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import requests
import subprocess
import shutil

# è§£å†³Windowsç»ˆç«¯ç¼–ç é—®é¢˜
if sys.platform == 'win32':
    import io

    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# å¯¼å…¥é…ç½®ç®¡ç†å™¨
try:
    from config_manager import config

    CONFIG_AVAILABLE = True
except ImportError:
    CONFIG_AVAILABLE = False
    print("è­¦å‘Š: æœªæ‰¾åˆ°config_manager.pyï¼Œå°†ä»…ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–å‘½ä»¤è¡Œå‚æ•°")


def setup_logger():
    """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
    log_dir = Path('log')
    log_dir.mkdir(exist_ok=True)

    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_file = log_dir / f'translation_{timestamp}.log'

    formatter = logging.Formatter('%(message)s')

    file_handler = logging.FileHandler(log_file, mode='w', encoding='utf-8')
    file_handler.setFormatter(formatter)
    file_handler.setLevel(logging.INFO)

    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    console_handler.setLevel(logging.INFO)

    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)

    return log_file


def cleanup_old_logs(log_dir, keep_days=7, auto_cleanup=False):
    """
    æ¸…ç†æ—§æ—¥å¿—æ–‡ä»¶

    Args:
        log_dir: æ—¥å¿—ç›®å½•è·¯å¾„
        keep_days: ä¿ç•™æœ€è¿‘å‡ å¤©çš„æ—¥å¿—ï¼ˆé»˜è®¤7å¤©ï¼‰
        auto_cleanup: æ˜¯å¦è‡ªåŠ¨æ¸…ç†ï¼ˆé»˜è®¤Falseï¼Œéœ€è¦é…ç½®å¯ç”¨ï¼‰

    Returns:
        int: åˆ é™¤çš„æ–‡ä»¶æ•°é‡
    """
    if not auto_cleanup:
        return 0

    log_dir = Path(log_dir)
    if not log_dir.exists():
        return 0

    # è·å–å½“å‰æ—¶é—´
    now = time.time()
    cutoff_time = now - (keep_days * 24 * 3600)

    deleted_count = 0
    deleted_size = 0

    # éå†æ—¥å¿—ç›®å½•
    for log_file in log_dir.glob('translation_*.log'):
        try:
            # è·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´
            file_mtime = log_file.stat().st_mtime

            # å¦‚æœæ–‡ä»¶è¶…è¿‡ä¿ç•™æœŸé™
            if file_mtime < cutoff_time:
                file_size = log_file.stat().st_size
                log_file.unlink()
                deleted_count += 1
                deleted_size += file_size
        except Exception as e:
            # åˆ é™¤å¤±è´¥æ—¶å¿½ç•¥ï¼Œç»§ç»­å¤„ç†å…¶ä»–æ–‡ä»¶
            pass

    if deleted_count > 0:
        size_mb = deleted_size / (1024 * 1024)
        print(f"ğŸ—‘ï¸  å·²æ¸…ç† {deleted_count} ä¸ªè¶…è¿‡ {keep_days} å¤©çš„æ—§æ—¥å¿—æ–‡ä»¶ï¼ˆé‡Šæ”¾ {size_mb:.1f}MBï¼‰")

    return deleted_count


class VideoTranslator:
    """è§†é¢‘æ‰¹é‡ç¿»è¯‘å™¨ï¼ˆæ”¯æŒå¹¶å‘æ¶¦è‰²ï¼‰"""

    def __init__(self, service_url='http://127.0.0.1:50515', deepseek_key=None,
                 use_polish=False, concurrent_polish=10,
                 enable_vocal_separation=False, vocal_separation_model='htdemucs', vocal_separation_device='auto',
                 vocal_separation_chunk_sec=1800,
                 clear_cuda_cache_before_tasks=False,
                 asr_chunk_sec=0, asr_chunk_overlap_sec=0.0,
                 manage_models=False, unload_models_after_tasks=False, model_load_timeout=3600,
                 subtitle_format: str = 'srt'):
        self.service_url = service_url

        # ä¼˜å…ˆçº§ï¼šå‘½ä»¤è¡Œå‚æ•° > ç¯å¢ƒå˜é‡ > config.ini
        if deepseek_key:
            self.deepseek_key = deepseek_key
        elif os.getenv('DEEPSEEK_API_KEY'):
            self.deepseek_key = os.getenv('DEEPSEEK_API_KEY')
        elif CONFIG_AVAILABLE:
            self.deepseek_key = config.deepseek_api_key
        else:
            self.deepseek_key = None

        self.use_polish = use_polish and self.deepseek_key
        self.concurrent_polish = concurrent_polish  # å¹¶å‘æ•°

        # å¯é€‰ï¼šäººå£°åˆ†ç¦»ï¼ˆDemucsï¼‰ç”¨äºæå‡å˜ˆæ‚/èƒŒæ™¯éŸ³ä¹åœºæ™¯è¯†åˆ«æ•ˆæœ
        self.enable_vocal_separation = enable_vocal_separation
        self.vocal_separation_model = vocal_separation_model
        self.vocal_separation_device = (vocal_separation_device or 'auto').lower()
        try:
            self.vocal_separation_chunk_sec = int(vocal_separation_chunk_sec)
        except Exception:
            self.vocal_separation_chunk_sec = 1800
        if self.vocal_separation_chunk_sec <= 0:
            self.vocal_separation_chunk_sec = 1800
        self.clear_cuda_cache_before_tasks = bool(clear_cuda_cache_before_tasks)
        self.asr_chunk_sec = int(asr_chunk_sec or 0)
        self.asr_chunk_overlap_sec = float(asr_chunk_overlap_sec or 0.0)
        self.manage_models = bool(manage_models)
        self.unload_models_after_tasks = bool(unload_models_after_tasks)
        self.model_load_timeout = int(model_load_timeout or 3600)
        self.subtitle_format = (subtitle_format or 'srt').strip().lower()
        if self.subtitle_format not in ('srt', 'ass'):
            self.subtitle_format = 'srt'

        # çº¿ç¨‹æ± ç”¨äºå¹¶å‘æ¶¦è‰²
        if self.use_polish:
            self.polish_executor = ThreadPoolExecutor(max_workers=concurrent_polish)
            self.polish_lock = threading.Lock()  # ç”¨äºæ—¥å¿—åŒæ­¥

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total': 0,
            'success': 0,
            'failed': 0,
            'skipped': 0,
            'start_time': None,
            'end_time': None
        }

        # æ”¯æŒçš„è§†é¢‘æ ¼å¼
        self.video_extensions = {'.mp4', '.avi', '.mkv', '.mov', '.flv', '.wmv', '.webm', '.m4v'}

        # è¿›åº¦ç®¡ç†
        self.progress_dir = Path('.progress')
        self.progress_dir.mkdir(exist_ok=True)
        self.progress_file = None
        self.progress_data = {}

    def __del__(self):
        """æ¸…ç†çº¿ç¨‹æ± """
        if hasattr(self, 'polish_executor'):
            self.polish_executor.shutdown(wait=True)

    def clear_cuda_cache(self, stage: str):
        """æ¸…ç† CUDA æ˜¾å­˜ç¼“å­˜ï¼ˆå°½é‡å‡å°‘ OOM æ¦‚ç‡ï¼‰"""
        if not self.clear_cuda_cache_before_tasks:
            return

        # 1) å½“å‰è¿›ç¨‹ï¼ˆè‹¥å®‰è£…äº† torchï¼‰
        try:
            import gc

            gc.collect()
        except Exception:
            pass

        try:
            import torch  # type: ignore

            if torch.cuda.is_available():
                try:
                    torch.cuda.empty_cache()
                except Exception:
                    pass
                try:
                    torch.cuda.ipc_collect()
                except Exception:
                    pass
        except Exception:
            pass

        # 2) æœåŠ¡ç«¯è¿›ç¨‹ï¼ˆå¦‚æœæä¾›äº† /gpu/clearï¼‰
        try:
            response = requests.post(
                f"{self.service_url}/gpu/clear",
                json={'stage': stage},
                timeout=10
            )
            if response.status_code == 200:
                data = response.json() or {}
                if data.get('cuda_available') and data.get('free_bytes') and data.get('total_bytes'):
                    free_gb = data['free_bytes'] / (1024 ** 3)
                    total_gb = data['total_bytes'] / (1024 ** 3)
                    logging.info(f"    [GPU] å·²æ¸…ç†ç¼“å­˜: {stage}ï¼ˆfree {free_gb:.1f}GB / total {total_gb:.1f}GBï¼‰")
        except Exception:
            # ä¸å½±å“ä¸»æµç¨‹
            pass

    def _service_models_load(self, models: list[str]) -> bool:
        """è®©æœåŠ¡ç«¯æŒ‰éœ€åŠ è½½æŒ‡å®šæ¨¡å‹ï¼ˆéœ€è¦ server_optimized.py æ”¯æŒ /models/loadï¼‰ã€‚"""
        try:
            resp = requests.post(
                f"{self.service_url}/models/load",
                json={'models': models},
                timeout=30
            )
        except Exception as e:
            logging.error(f"  Ã— è¯·æ±‚æœåŠ¡ç«¯åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            return False

        if resp.status_code == 404:
            logging.error("  Ã— æœåŠ¡ç«¯ä¸æ”¯æŒ /models/loadï¼šè¯·æ›´æ–° server_optimized.py")
            return False

        if resp.status_code != 200:
            try:
                logging.error(f"  Ã— æœåŠ¡ç«¯åŠ è½½æ¨¡å‹å¤±è´¥: {resp.status_code} {resp.json()}")
            except Exception:
                logging.error(f"  Ã— æœåŠ¡ç«¯åŠ è½½æ¨¡å‹å¤±è´¥: {resp.status_code} {resp.text[:500]}")
            return False

        return bool((resp.json() or {}).get('success', True))

    def _service_models_unload(self, models: list[str]) -> bool:
        """è®©æœåŠ¡ç«¯å¸è½½æŒ‡å®šæ¨¡å‹ä»¥é‡Šæ”¾æ˜¾å­˜ï¼ˆéœ€è¦ /models/unloadï¼‰ã€‚"""
        try:
            resp = requests.post(
                f"{self.service_url}/models/unload",
                json={'models': models},
                timeout=30
            )
        except Exception:
            return False

        if resp.status_code != 200:
            return False
        return True

    def _wait_models_ready(self, want_asr: bool, want_translation: bool, timeout: int) -> bool:
        """ç­‰å¾…æœåŠ¡ç«¯æŒ‡å®šæ¨¡å‹å°±ç»ªã€‚"""
        start = time.time()
        last_log = 0.0
        while True:
            if time.time() - start > timeout:
                logging.error(f"  Ã— ç­‰å¾…æ¨¡å‹åŠ è½½è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰")
                return False
            try:
                # æ¨¡å‹é¦–æ¬¡ä¸‹è½½/åŠ è½½æ—¶ï¼ŒæœåŠ¡ç«¯å¯èƒ½çŸ­æš‚æ— å“åº”ï¼ˆGIL/IO/CPUå ç”¨ï¼‰ï¼Œé€‚å½“æ”¾å®½ read timeout
                h = requests.get(f"{self.service_url}/health", timeout=(3, 30)).json()
            except Exception as e:
                if time.time() - last_log >= 10:
                    logging.info(f"    â€¦ ç­‰å¾…æœåŠ¡å“åº”: {e}")
                    last_log = time.time()
                time.sleep(2)
                continue

            if h.get('phase') == 'error':
                logging.error(f"  Ã— æ¨¡å‹åŠ è½½å¤±è´¥: {h.get('error') or 'æœªçŸ¥é”™è¯¯'}")
                return False

            asr_ready = bool(h.get('asr_ready'))
            translation_ready = bool(h.get('translation_ready'))
            if (not want_asr or asr_ready) and (not want_translation or translation_ready):
                return True

            now = time.time()
            if now - last_log >= 10:
                phase = h.get('phase')
                pct = int((h.get('progress') or 0) * 100)
                msg = h.get('message') or ''
                logging.info(f"    â€¦ æ¨¡å‹åŠ è½½ä¸­: {phase} ({pct}%) {msg}".rstrip())
                last_log = now
            time.sleep(2)

    def ensure_models(self, want_asr: bool = False, want_translation: bool = False) -> bool:
        """æŒ‰éœ€åŠ è½½æœåŠ¡ç«¯æ¨¡å‹ï¼Œå¹¶ç­‰å¾…å°±ç»ªã€‚"""
        models: list[str] = []
        if want_asr:
            models.append('asr')
        if want_translation:
            models.append('translation')
        if not models:
            return True

        if not self._service_models_load(models):
            return False
        return self._wait_models_ready(want_asr, want_translation, timeout=self.model_load_timeout)

    def load_progress(self, task_name):
        """åŠ è½½è¿›åº¦æ–‡ä»¶"""
        self.progress_file = self.progress_dir / f'{task_name}.json'

        if self.progress_file.exists():
            try:
                with open(self.progress_file, 'r', encoding='utf-8') as f:
                    self.progress_data = json.load(f)
                logging.info(f"âœ“ åŠ è½½è¿›åº¦æ–‡ä»¶: {self.progress_file.name}")

                completed = sum(1 for v in self.progress_data.values() if v.get('status') == 'completed')
                failed = sum(1 for v in self.progress_data.values() if v.get('status') == 'failed')
                if completed > 0 or failed > 0:
                    logging.info(f"  å·²å®Œæˆ: {completed}, å·²å¤±è´¥: {failed}")
            except:
                self.progress_data = {}
        else:
            self.progress_data = {}

    def save_progress(self):
        """ä¿å­˜è¿›åº¦"""
        if self.progress_file:
            with open(self.progress_file, 'w', encoding='utf-8') as f:
                json.dump(self.progress_data, f, ensure_ascii=False, indent=2)

    def update_video_status(self, video_name, status, **kwargs):
        """æ›´æ–°è§†é¢‘çŠ¶æ€"""
        self.progress_data[video_name] = {
            'status': status,
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            **kwargs
        }
        self.save_progress()

    def should_skip_video(self, video_path, srt_path):
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡è¯¥è§†é¢‘"""
        video_name = video_path.name

        # æ£€æŸ¥å­—å¹•æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if srt_path.exists():
            return True, 'å­—å¹•æ–‡ä»¶å·²å­˜åœ¨'

        if video_name not in self.progress_data:
            return False, None

        status = self.progress_data[video_name].get('status')

        if status == 'completed':
            return False, 'ä¸Šæ¬¡å®Œæˆä½†æ–‡ä»¶ç¼ºå¤±ï¼Œé‡æ–°å¤„ç†'
        elif status == 'processing':
            return False, 'ä¸Šæ¬¡æœªå®Œæˆï¼Œé‡æ–°å¤„ç†'
        elif status == 'failed':
            retry_count = self.progress_data[video_name].get('retry_count', 0)
            if retry_count >= 3:
                return True, f'å·²å¤±è´¥{retry_count}æ¬¡ï¼Œè·³è¿‡'
            else:
                return False, f'é‡è¯•ç¬¬{retry_count + 1}æ¬¡'

        return False, None

    def check_service(self, wait_ready=False, wait_timeout=3600, poll_interval=2):
        """æ£€æŸ¥ç¿»è¯‘æœåŠ¡æ˜¯å¦å¯ç”¨ï¼ˆå¯é€‰ç­‰å¾…æœåŠ¡å°±ç»ªï¼‰"""
        start_time = time.time()
        last_status = None
        last_log_time = 0.0
        last_error_log_time = 0.0

        while True:
            try:
                response = requests.get(f"{self.service_url}/health", timeout=5)
                if response.status_code != 200:
                    logging.error(f"Ã— ç¿»è¯‘æœåŠ¡å¼‚å¸¸: {response.status_code}")
                    return False

                data = response.json()

                if data.get('ready'):
                    logging.info("âœ“ ç¿»è¯‘æœåŠ¡æ­£å¸¸è¿è¡Œ")
                    return True

                if not wait_ready:
                    if self.manage_models:
                        logging.info("âœ“ ç¿»è¯‘æœåŠ¡æ­£å¸¸è¿è¡Œï¼ˆæ¨¡å‹å°†æŒ‰éœ€åŠ è½½ï¼‰")
                        return True
                    logging.error("Ã— ç¿»è¯‘æœåŠ¡æœªå°±ç»ªï¼Œè¯·ç­‰å¾…æ¨¡å‹åŠ è½½")
                    return False

                phase = data.get('phase')
                progress = data.get('progress')
                message = data.get('message')
                error = data.get('error')

                # ä»…åœ¨çŠ¶æ€å˜åŒ–æ—¶è¾“å‡ºï¼Œé¿å…åˆ·å±
                status = (phase, progress, message, error)
                now = time.time()
                if status != last_status or (now - last_log_time) >= 10:
                    pct = int((progress or 0) * 100)
                    logging.info(f"â€¦ ç­‰å¾…æœåŠ¡å°±ç»ª: {phase} ({pct}%) {message or ''}".rstrip())
                    last_status = status
                    last_log_time = now

                if phase == 'error':
                    logging.error(f"Ã— æ¨¡å‹åŠ è½½å¤±è´¥: {error or 'æœªçŸ¥é”™è¯¯'}")
                    return False

            except Exception as e:
                if not wait_ready:
                    logging.error(f"Ã— æ— æ³•è¿æ¥åˆ°ç¿»è¯‘æœåŠ¡: {e}")
                    logging.error("  è¯·ç¡®ä¿æœåŠ¡æ­£åœ¨è¿è¡Œ: python server_optimized.py")
                    return False
                now = time.time()
                if (now - last_error_log_time) >= 10:
                    logging.info(f"â€¦ ç­‰å¾…ç¿»è¯‘æœåŠ¡å¯åŠ¨: {e}")
                    last_error_log_time = now

            if time.time() - start_time > wait_timeout:
                logging.error(f"Ã— ç­‰å¾…ç¿»è¯‘æœåŠ¡å°±ç»ªè¶…æ—¶ï¼ˆ{wait_timeout}ç§’ï¼‰")
                logging.error("  ä½ å¯ä»¥ï¼š1) ç»§ç»­ç­‰å¾…å¹¶é‡è¯• 2) æŸ¥çœ‹ server.log 3) æ¢æ›´å°çš„ç¿»è¯‘æ¨¡å‹")
                return False

            time.sleep(poll_interval)

    def extract_audio(self, video_path, output_path, sample_rate=16000, channels=1):
        """ä»è§†é¢‘æå–éŸ³é¢‘"""
        try:
            cmd = [
                'ffmpeg', '-i', video_path,
                '-vn', '-acodec', 'pcm_s16le',
                '-ar', str(sample_rate), '-ac', str(channels),
                '-y', output_path
            ]

            subprocess.run(
                cmd,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                check=True
            )
            return True
        except subprocess.CalledProcessError as e:
            logging.error(f"  Ã— éŸ³é¢‘æå–å¤±è´¥: {e}")
            return False
        except FileNotFoundError:
            logging.error("  Ã— æ‰¾ä¸åˆ°ffmpegï¼Œè¯·å®‰è£…ffmpegå¹¶æ·»åŠ åˆ°PATH")
            return False

    def separate_vocals(self, input_audio_path: Path, output_wav_path: Path):
        """
        ä½¿ç”¨ Demucs åšäººå£°åˆ†ç¦»ï¼Œè¾“å‡º 16kHz/mono WAV ä¾› ASR ä½¿ç”¨ã€‚

        éœ€è¦é¢å¤–å®‰è£…ï¼š
          pip install demucs
        """
        try:
            import demucs  # noqa: F401
        except Exception as e:
            raise RuntimeError("å·²å¯ç”¨äººå£°åˆ†ç¦»ï¼Œä½†æœªå®‰è£… demucsï¼šè¯·å…ˆè¿è¡Œ `pip install demucs`") from e

        def _ffprobe_duration_sec(path: Path) -> float | None:
            try:
                p = subprocess.run(
                    [
                        'ffprobe',
                        '-v', 'error',
                        '-show_entries', 'format=duration',
                        '-of', 'default=noprint_wrappers=1:nokey=1',
                        str(path),
                    ],
                    capture_output=True,
                    text=True,
                    check=False,
                )
                if p.returncode != 0:
                    return None
                s = (p.stdout or '').strip()
                if not s:
                    return None
                return float(s)
            except Exception:
                return None

        # é€šè¿‡ç¯å¢ƒå˜é‡æ§åˆ¶ Demucs æ˜¯å¦ä½¿ç”¨ GPUï¼ˆé¿å…ä¾èµ–ä¸åŒç‰ˆæœ¬çš„ CLI å‚æ•°ï¼‰
        env = os.environ.copy()
        if self.vocal_separation_device == 'cpu':
            env['CUDA_VISIBLE_DEVICES'] = ''
        elif self.vocal_separation_device == 'cuda':
            # å°½é‡å‡å°‘æ˜¾å­˜ç¢ç‰‡å¯¼è‡´çš„ OOMï¼ˆä¸è¦†ç›–ç”¨æˆ·å·²æœ‰è®¾ç½®ï¼‰
            # æ³¨ï¼šPYTORCH_CUDA_ALLOC_CONF å·²å¼ƒç”¨ï¼Œæ”¹ç”¨ PYTORCH_ALLOC_CONF
            env.setdefault('PYTORCH_ALLOC_CONF', 'max_split_size_mb:128')

        def _run_demucs_one(track_path: Path, out_16k_wav_path: Path, label: str | None = None):
            tmp_dir = tempfile.mkdtemp(prefix='demucs_')
            success = False
            try:
                cmd = [
                    sys.executable, '-m', 'demucs.separate',
                    '-n', self.vocal_separation_model,
                    '--two-stems', 'vocals',
                    '-o', tmp_dir,
                    str(track_path)
                ]
                demucs_log_path = Path(tmp_dir) / 'demucs.log'
                env.setdefault('PYTHONUNBUFFERED', '1')

                is_tty = sys.stdout.isatty()
                percent_re = re.compile(r'(\d{1,3})%')
                last_percent = None
                next_log_percent = 10
                spinner = ['|', '/', '-', '\\']
                spinner_i = 0
                start_time = time.time()
                log_offset = 0
                log_buf = ''

                prefix = "    [Demucs]" if not label else f"    [Demucs {label}]"

                def _print_progress(text: str):
                    if not is_tty:
                        return
                    sys.stdout.write(text)
                    sys.stdout.flush()

                with open(demucs_log_path, 'wb') as demucs_log:
                    proc = subprocess.Popen(
                        cmd,
                        env=env,
                        stdout=demucs_log,
                        stderr=subprocess.STDOUT,
                    )

                    while True:
                        rc = proc.poll()

                        # å°è¯•ä» demucs.log è¯»å–æ–°å¢å†…å®¹å¹¶è§£æç™¾åˆ†æ¯”
                        try:
                            with open(demucs_log_path, 'rb') as f:
                                f.seek(log_offset, os.SEEK_SET)
                                data = f.read()
                                log_offset = f.tell()
                            if data:
                                chunk = data.decode('utf-8', errors='replace')
                                log_buf = (log_buf + chunk)[-50_000:]  # ä»…ä¿ç•™æœ«å°¾ï¼Œé¿å…æ— é™å¢é•¿
                                matches = percent_re.findall(log_buf)
                                if matches:
                                    p = int(matches[-1])
                                    if 0 <= p <= 100:
                                        if last_percent is None:
                                            last_percent = p
                                        else:
                                            # tqdm å¯èƒ½ä¼šæœ‰å¤šæ®µè¿›åº¦æ¡ï¼Œå…è®¸åœ¨æ¥è¿‘å®Œæˆåé‡ç½®
                                            if p < last_percent and last_percent >= 95 and p <= 5:
                                                last_percent = p
                                                next_log_percent = 10
                                            else:
                                                last_percent = p
                        except Exception:
                            pass

                        elapsed = int(time.time() - start_time)
                        if last_percent is not None:
                            bar_len = 24
                            filled = int(bar_len * last_percent / 100)
                            bar = '#' * filled + '.' * (bar_len - filled)
                            _print_progress(f"\r{prefix} {last_percent:3d}% |{bar}| {elapsed}s")

                            # notebook/éTTYï¼šæ¯10%è®°å½•ä¸€æ¬¡ï¼Œé¿å…åˆ·å±
                            if (not is_tty) and last_percent >= next_log_percent:
                                logging.info(f"{prefix} è¿›åº¦: {last_percent}%")
                                next_log_percent += 10
                        else:
                            _print_progress(f"\r{prefix} {spinner[spinner_i % len(spinner)]} è¿è¡Œä¸­... {elapsed}s")
                            spinner_i += 1

                        if rc is not None:
                            break
                        time.sleep(0.5)

                    proc.wait()

                if is_tty:
                    # æ¸…ç†è¿›åº¦è¡Œ
                    sys.stdout.write("\n")
                    sys.stdout.flush()

                if proc.returncode != 0:
                    # é¿å… stdout PIPE å¡æ­»ï¼šè¾“å‡ºå†™å…¥æ–‡ä»¶ï¼Œå¤±è´¥æ—¶ä»…æ‰“å°æœ«å°¾
                    tail_text = ''
                    try:
                        with open(demucs_log_path, 'rb') as f:
                            f.seek(0, os.SEEK_END)
                            size = f.tell()
                            f.seek(max(0, size - 200_000), os.SEEK_SET)  # åªè¯»æœ«å°¾200KB
                            data = f.read()
                        tail_text = data.decode('utf-8', errors='replace').strip()
                    except Exception:
                        tail_text = ''
                    if tail_text:
                        tail = "\n".join(tail_text.splitlines()[-200:])
                        logging.error("  Ã— Demucs è¾“å‡ºï¼ˆæœ€å200è¡Œï¼‰ï¼š\n" + tail)
                    logging.error(f"  ! Demucs æ—¥å¿—æ–‡ä»¶: {demucs_log_path}")
                    if 'TorchCodec is required' in tail_text or "No module named 'torchcodec'" in tail_text:
                        raise RuntimeError("Demucs ä¾èµ– torchcodec ä¿å­˜éŸ³é¢‘ï¼šè¯·å…ˆè¿è¡Œ `pip install torchcodec` å†é‡è¯•") from None
                    if proc.returncode == -9:
                        raise RuntimeError("Demucs è¢«ç³»ç»Ÿç»ˆæ­¢ï¼ˆexit code=-9ï¼‰ï¼šé€šå¸¸æ˜¯ CPU å†…å­˜ä¸è¶³ï¼ˆOOM killï¼‰ã€‚å»ºè®®å¯ç”¨åˆ†æ®µäººå£°åˆ†ç¦»æˆ–ç¼©çŸ­åˆ†æ®µæ—¶é•¿ã€‚") from None
                    raise RuntimeError(f"Demucs æ‰§è¡Œå¤±è´¥ï¼ˆexit code={proc.returncode}ï¼‰: {' '.join(cmd)}")

                tmp_dir_path = Path(tmp_dir)
                candidates = list(tmp_dir_path.rglob('vocals.wav'))
                if not candidates:
                    candidates = [p for p in tmp_dir_path.rglob('vocals.*') if p.is_file()]
                if not candidates:
                    raise FileNotFoundError(f"Demucs è¾“å‡ºæœªæ‰¾åˆ°ï¼š{tmp_dir}")

                vocals_path = candidates[0]
                cmd = [
                    'ffmpeg', '-i', str(vocals_path),
                    '-vn', '-acodec', 'pcm_s16le',
                    '-ar', '16000', '-ac', '1',
                    '-y', str(out_16k_wav_path)
                ]
                subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                if not out_16k_wav_path.exists():
                    raise FileNotFoundError(f"äººå£°åˆ†ç¦»è¾“å‡ºæœªç”Ÿæˆ: {out_16k_wav_path}")
                success = True
            finally:
                if success:
                    shutil.rmtree(tmp_dir, ignore_errors=True)
                else:
                    logging.error(f"  ! Demucs ä¸´æ—¶ç›®å½•å·²ä¿ç•™ç”¨äºæ’æŸ¥: {tmp_dir}")

        # è¶…é•¿éŸ³é¢‘ï¼šé¿å… demucs/torchaudio ä¸€æ¬¡æ€§åŠ è½½åˆ°å†…å­˜å¯¼è‡´ OOM killï¼ˆexit code=-9ï¼‰
        size_bytes = None
        try:
            size_bytes = input_audio_path.stat().st_size
        except Exception:
            size_bytes = None
        duration_sec = _ffprobe_duration_sec(input_audio_path)

        # è§¦å‘æ¡ä»¶ï¼š>1å°æ—¶ æˆ– >512MBï¼ˆçº¦ 48min çš„ 44.1kHz/2ch/16bit PCMï¼‰
        enable_chunk = True
        chunk_sec = int(getattr(self, 'vocal_separation_chunk_sec', 1800) or 1800)
        chunk_threshold_sec = 3600
        size_threshold_bytes = 512 * 1024 * 1024
        should_chunk = (
            enable_chunk
            and chunk_sec > 0
            and (
                (duration_sec is not None and duration_sec >= chunk_threshold_sec)
                or (size_bytes is not None and size_bytes >= size_threshold_bytes)
            )
        )

        if not should_chunk:
            _run_demucs_one(input_audio_path, output_wav_path)
            return

        work_dir = tempfile.mkdtemp(prefix='demucs_chunks_')
        work_path = Path(work_dir)
        success = False
        try:
            if duration_sec is not None:
                logging.info(f"    [Demucs] æ£€æµ‹åˆ°é•¿éŸ³é¢‘ï¼ˆ{duration_sec/60:.1f}åˆ†é’Ÿï¼‰ï¼Œå¯ç”¨åˆ†æ®µå¤„ç†ï¼š{chunk_sec}s/æ®µ")
            elif size_bytes is not None:
                logging.info(f"    [Demucs] æ£€æµ‹åˆ°å¤§éŸ³é¢‘ï¼ˆ{size_bytes/(1024**3):.2f}GBï¼‰ï¼Œå¯ç”¨åˆ†æ®µå¤„ç†ï¼š{chunk_sec}s/æ®µ")
            else:
                logging.info(f"    [Demucs] å¯ç”¨åˆ†æ®µå¤„ç†ï¼š{chunk_sec}s/æ®µ")

            chunk_pattern = work_path / 'chunk_%06d.wav'
            cmd = [
                'ffmpeg',
                '-i', str(input_audio_path),
                '-vn',
                '-acodec', 'pcm_s16le',
                '-ar', '44100', '-ac', '2',
                '-f', 'segment',
                '-segment_time', str(int(chunk_sec)),
                '-reset_timestamps', '1',
                '-y', str(chunk_pattern),
            ]
            subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

            chunks = sorted(work_path.glob('chunk_*.wav'))
            if not chunks:
                raise RuntimeError("åˆ†æ®µå¤±è´¥ï¼šæœªç”Ÿæˆä»»ä½•éŸ³é¢‘åˆ†æ®µæ–‡ä»¶")

            # åˆ†æ®µç”Ÿæˆåå³å¯åˆ é™¤åŸå§‹å¤§æ–‡ä»¶ï¼Œé¿å…å ç”¨ç£ç›˜ï¼ˆè‹¥å¤±è´¥å¯ä»è§†é¢‘é‡æ–°æå–ï¼‰
            try:
                if size_bytes is not None and size_bytes >= size_threshold_bytes and input_audio_path.exists():
                    input_audio_path.unlink(missing_ok=True)
            except Exception:
                pass

            chunk_vocals = []
            total = len(chunks)
            for i, chunk_path in enumerate(chunks, 1):
                label = f"{i}/{total}"
                out_chunk = work_path / f"vocals_{i:06d}.wav"
                _run_demucs_one(chunk_path, out_chunk, label=label)
                chunk_vocals.append(out_chunk)

            concat_list = work_path / 'concat.txt'
            with open(concat_list, 'w', encoding='utf-8') as f:
                for p in chunk_vocals:
                    pp = str(p).replace("'", "'\\''")
                    f.write(f"file '{pp}'\n")

            # ä¼˜å…ˆç”¨ -c copyï¼ˆåŒä¸€ç¼–ç å‚æ•°çš„ WAV å¯ç›´æ¥æ‹¼æ¥ï¼‰ï¼Œå¤±è´¥åˆ™å›é€€åˆ°é‡ç¼–ç 
            concat_cmd = [
                'ffmpeg',
                '-f', 'concat',
                '-safe', '0',
                '-i', str(concat_list),
                '-c', 'copy',
                '-y', str(output_wav_path),
            ]
            try:
                subprocess.run(concat_cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            except Exception:
                concat_cmd = [
                    'ffmpeg',
                    '-f', 'concat',
                    '-safe', '0',
                    '-i', str(concat_list),
                    '-vn',
                    '-acodec', 'pcm_s16le',
                    '-ar', '16000', '-ac', '1',
                    '-y', str(output_wav_path),
                ]
                subprocess.run(concat_cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

            if not output_wav_path.exists():
                raise FileNotFoundError(f"äººå£°åˆ†ç¦»è¾“å‡ºæœªç”Ÿæˆ: {output_wav_path}")

            success = True
        finally:
            if success:
                shutil.rmtree(work_dir, ignore_errors=True)
            else:
                logging.error(f"  ! Demucs åˆ†æ®µä¸´æ—¶ç›®å½•å·²ä¿ç•™ç”¨äºæ’æŸ¥: {work_dir}")

    @staticmethod
    def _trim_text_overlap(prev_text: str, text: str, max_words: int = 12) -> str:
        """
        å¤„ç†åˆ†å—è¯†åˆ«æ—¶çš„è¾¹ç•Œé‡å¤ï¼šè‹¥ä¸Šä¸€æ®µå°¾éƒ¨è‹¥å¹²å•è¯ä¸æœ¬æ®µå¼€å¤´é‡å¤ï¼Œåˆ™ä»æœ¬æ®µç§»é™¤è¯¥é‡å¤éƒ¨åˆ†ã€‚
        """
        prev_text = (prev_text or '').strip()
        text = (text or '').strip()
        if not prev_text or not text:
            return text

        prev_words = prev_text.split()
        words = text.split()
        if not prev_words or not words:
            return text

        def _norm_word(w: str) -> str:
            return re.sub(r'^[\\W_]+|[\\W_]+$', '', w).lower()

        prev_norm = [_norm_word(w) for w in prev_words]
        norm = [_norm_word(w) for w in words]
        max_k = min(max_words, len(prev_norm), len(norm))
        for k in range(max_k, 0, -1):
            if prev_norm[-k:] == norm[:k] and all(prev_norm[-k:]) and all(norm[:k]):
                return " ".join(words[k:]).lstrip()
        return text

    def _transcribe_http(self, audio_file, filename: str, language: str | None, timeout: int = 3600):
        """è°ƒç”¨æœåŠ¡ç«¯ /transcribeï¼ˆaudio_file ä¸ºæ–‡ä»¶å¯¹è±¡æˆ– BytesIOï¼‰ã€‚"""
        files = {'audio': (filename, audio_file)}
        data = {}
        if language and language != 'auto':
            data['language'] = language

        response = requests.post(
            f"{self.service_url}/transcribe",
            files=files,
            data=data,
            timeout=timeout
        )

        if response.status_code == 200:
            return response.json()

        logging.error(f"\n  Ã— è¯†åˆ«å¤±è´¥: {response.status_code}")
        # å°½é‡æ‰“å°æœåŠ¡ç«¯è¿”å›çš„é”™è¯¯ä¿¡æ¯ï¼Œæ–¹ä¾¿åœ¨æ—  server.log çš„ç¯å¢ƒæ’æŸ¥
        try:
            data = response.json()
            if isinstance(data, dict):
                err = data.get('error') or data
            else:
                err = data
            logging.error(f"    æœåŠ¡ç«¯é”™è¯¯: {err}")
            if isinstance(data, dict) and data.get('traceback'):
                logging.error("    æœåŠ¡ç«¯ tracebackï¼ˆæœ«å°¾ï¼‰ï¼š\n" + str(data.get('traceback'))[-2000:])
        except Exception:
            body = (response.text or '').strip()
            if body:
                body = body[:2000]
                logging.error(f"    æœåŠ¡ç«¯å“åº”: {body}")
        return None

    def transcribe_single(self, audio_path: str, language: str | None = None):
        """è¯­éŸ³è¯†åˆ«ï¼ˆæ•´æ®µï¼Œé˜»å¡ç­‰å¾…æœåŠ¡ç«¯è¿”å›ï¼‰ã€‚"""
        try:
            with open(audio_path, 'rb') as f:
                return self._transcribe_http(f, Path(audio_path).name, language, timeout=3600)
        except requests.exceptions.Timeout:
            logging.error("\n  Ã— è¯†åˆ«è¶…æ—¶ï¼ˆè§†é¢‘å¤ªé•¿ï¼Œè¶…è¿‡1å°æ—¶å¤„ç†æ—¶é—´ï¼‰")
            return None
        except Exception as e:
            logging.error(f"\n  Ã— è¯†åˆ«é”™è¯¯: {e}")
            return None

    def transcribe_chunked(self, audio_path: str, chunk_sec: int, overlap_sec: float = 0.0, language: str | None = None):
        """è¯­éŸ³è¯†åˆ«ï¼ˆåˆ†å—ä¸Šä¼ ï¼Œæ˜¾ç¤ºè¿›åº¦ï¼›ä¹Ÿå¯é™ä½é•¿éŸ³é¢‘å¯¼è‡´çš„ 500/OOM æ¦‚ç‡ï¼‰ã€‚"""
        import io
        import math
        import wave

        try:
            chunk_sec = int(chunk_sec)
            overlap_sec = float(overlap_sec or 0.0)
        except Exception:
            return self.transcribe_single(audio_path, language=language)

        if chunk_sec <= 0:
            return self.transcribe_single(audio_path, language=language)
        if overlap_sec < 0:
            overlap_sec = 0.0
        if overlap_sec >= chunk_sec:
            overlap_sec = max(0.0, chunk_sec - 0.1)

        try:
            with wave.open(audio_path, 'rb') as wf:
                nchannels = wf.getnchannels()
                sampwidth = wf.getsampwidth()
                framerate = wf.getframerate()
                nframes = wf.getnframes()

                if framerate <= 0 or nframes <= 0:
                    return self.transcribe_single(audio_path, language=language)

                total_sec = nframes / float(framerate)
                chunk_frames = max(1, int(chunk_sec * framerate))
                overlap_frames = max(0, int(overlap_sec * framerate))
                step_frames = max(1, chunk_frames - overlap_frames)

                if nframes <= chunk_frames:
                    return self.transcribe_single(audio_path, language=language)

                total_chunks = int(math.ceil((nframes - chunk_frames) / step_frames)) + 1

                is_tty = sys.stdout.isatty()
                bar_len = 24
                start_time = time.time()
                last_percent = -1

                def _print_progress(text: str):
                    if not is_tty:
                        return
                    sys.stdout.write(text)
                    sys.stdout.flush()

                merged_segments: list[dict] = []
                merged_text = ''
                detected_language = None
                detected_prob = None
                total_processing_ms = 0

                start_frame = 0
                chunk_index = 0
                while start_frame < nframes:
                    end_frame = min(nframes, start_frame + chunk_frames)
                    chunk_start_sec = start_frame / float(framerate)
                    chunk_end_sec = end_frame / float(framerate)

                    chunk_index += 1

                    wf.setpos(start_frame)
                    frames = wf.readframes(end_frame - start_frame)
                    bio = io.BytesIO()
                    with wave.open(bio, 'wb') as out_wav:
                        out_wav.setnchannels(nchannels)
                        out_wav.setsampwidth(sampwidth)
                        out_wav.setframerate(framerate)
                        out_wav.writeframes(frames)
                    bio.seek(0)

                    lang_to_use = None
                    if language and language != 'auto':
                        lang_to_use = language
                    elif detected_language:
                        lang_to_use = detected_language

                    result = self._transcribe_http(
                        bio,
                        filename=f"chunk_{chunk_index}.wav",
                        language=lang_to_use,
                        timeout=3600
                    )
                    if not result or not result.get('success'):
                        if is_tty:
                            sys.stdout.write("\n")
                            sys.stdout.flush()
                        return None

                    if detected_language is None:
                        detected_language = result.get('language')
                        detected_prob = result.get('language_probability')
                    try:
                        total_processing_ms += int(result.get('processing_time_ms') or 0)
                    except Exception:
                        pass

                    for seg in result.get('segments', []) or []:
                        try:
                            seg_start = float(seg.get('start', 0.0)) + chunk_start_sec
                            seg_end = float(seg.get('end', 0.0)) + chunk_start_sec
                        except Exception:
                            continue
                        seg_text_raw = seg.get('text', '')
                        if not str(seg_text_raw).strip():
                            continue

                        if merged_segments:
                            last = merged_segments[-1]
                            last_end = float(last.get('end', 0.0))
                            if seg_end <= last_end + 0.02:
                                continue
                            if seg_start < last_end - 0.02:
                                trimmed = self._trim_text_overlap(last.get('text', ''), str(seg_text_raw))
                                if trimmed and trimmed != str(seg_text_raw).strip():
                                    seg_text_raw = trimmed
                                seg_start = max(seg_start, last_end)

                        if seg_end <= seg_start + 0.02:
                            continue

                        merged_segments.append({'start': seg_start, 'end': seg_end, 'text': seg_text_raw})
                        try:
                            merged_text += str(seg_text_raw)
                        except Exception:
                            pass

                    elapsed = int(time.time() - start_time)
                    percent = int(min(100.0, (chunk_end_sec / total_sec) * 100.0))
                    if is_tty and percent != last_percent:
                        filled = int(bar_len * percent / 100)
                        bar = '#' * filled + '.' * (bar_len - filled)
                        _print_progress(f"\r    [ASR] {percent:3d}% |{bar}| {elapsed}s (chunk {chunk_index}/{total_chunks})")
                        last_percent = percent
                    elif not is_tty:
                        filled = int(bar_len * percent / 100)
                        bar = '#' * filled + '.' * (bar_len - filled)
                        logging.info(f"    [ASR] {percent:3d}% |{bar}| {elapsed}s (chunk {chunk_index}/{total_chunks})")

                    if end_frame >= nframes:
                        break
                    start_frame += step_frames

                if is_tty:
                    sys.stdout.write("\n")
                    sys.stdout.flush()

                return {
                    'success': True,
                    'text': (merged_text or '').strip(),
                    'language': detected_language,
                    'language_probability': detected_prob,
                    'segments': merged_segments,
                    'processing_time_ms': total_processing_ms,
                }
        except wave.Error:
            return self.transcribe_single(audio_path, language=language)
        except Exception as e:
            logging.error(f"\n  Ã— åˆ†å—è¯†åˆ«é”™è¯¯: {e}")
            return self.transcribe_single(audio_path, language=language)

    def transcribe(self, audio_path: str, language: str | None = None):
        """è¯­éŸ³è¯†åˆ«ï¼ˆæ”¯æŒåˆ†å—è¿›åº¦æ¡ï¼‰ã€‚"""
        if self.asr_chunk_sec and self.asr_chunk_sec > 0:
            return self.transcribe_chunked(
                audio_path,
                chunk_sec=self.asr_chunk_sec,
                overlap_sec=self.asr_chunk_overlap_sec,
                language=language
            )
        return self.transcribe_single(audio_path, language=language)

    def translate_text(self, text, source_lang='en', target_lang='zh', max_retries=3):
        """ç¿»è¯‘æ–‡æœ¬ï¼ˆå¸¦é‡è¯•ï¼‰"""
        for attempt in range(max_retries):
            try:
                response = requests.post(
                    f"{self.service_url}/translate",
                    json={
                        'text': text,
                        'source_language': source_lang,
                        'target_language': target_lang
                    },
                    timeout=90
                )

                if response.status_code == 200:
                    result = response.json()
                    return result.get('translated_text', '')
                else:
                    if attempt < max_retries - 1:
                        time.sleep(2)
                        continue
                    return text
            except requests.exceptions.Timeout:
                if attempt < max_retries - 1:
                    time.sleep(2)
                else:
                    logging.warning(f"  ! ç¿»è¯‘è¶…æ—¶")
                    return text
            except Exception as e:
                if attempt < max_retries - 1:
                    time.sleep(2)
                else:
                    logging.warning(f"  ! ç¿»è¯‘å¤±è´¥: {e}")
                    return text
        return text

    def get_context_window(self, segments, index, window_size=2):
        """è·å–ä¸Šä¸‹æ–‡çª—å£"""
        start = max(0, index - window_size)
        end = min(len(segments), index + window_size + 1)

        context_before = []
        for i in range(start, index):
            if 'translated' in segments[i]:
                context_before.append(segments[i]['translated'])

        context_after = []
        for i in range(index + 1, end):
            context_after.append(segments[i]['text'])

        return context_before, context_after

    def polish_translation_with_context(self, text, translated, context_before, context_after,
                                        source_lang='en', target_lang='zh', max_retries=3):
        """ä½¿ç”¨DeepSeekæ¶¦è‰²ç¿»è¯‘ï¼ˆå¸¦ä¸Šä¸‹æ–‡ï¼‰"""
        if not self.use_polish:
            return translated

        lang_names = {'en': 'è‹±è¯­', 'zh': 'ä¸­æ–‡', 'ja': 'æ—¥è¯­', 'ko': 'éŸ©è¯­'}
        source_name = lang_names.get(source_lang, source_lang)
        target_name = lang_names.get(target_lang, target_lang)

        # æ„å»ºå¸¦ä¸Šä¸‹æ–‡çš„æç¤ºè¯
        context_str = ""
        if context_before:
            context_str += f"\nå‰æ–‡ï¼ˆå·²ç¿»è¯‘ï¼‰ï¼š\n" + "\n".join(f"- {c}" for c in context_before[-2:])

        if context_after:
            context_str += f"\n\nåæ–‡ï¼ˆåŸæ–‡ï¼‰ï¼š\n" + "\n".join(f"- {c}" for c in context_after[:2])

        prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„{target_name}å½±è§†å­—å¹•ç¿»è¯‘ä¸“å®¶ã€‚è¯·ç»“åˆä¸Šä¸‹æ–‡ï¼Œå°†ä»¥ä¸‹{source_name}å¯¹è¯ç¿»è¯‘å¾—æ›´åœ°é“ã€è‡ªç„¶ã€‚
{context_str}

å½“å‰å¥å­ï¼š
åŸæ–‡ï¼š{text}
æœºå™¨ç¿»è¯‘ï¼š{translated}

æ¶¦è‰²è¦æ±‚ï¼š
1. ç»“åˆä¸Šä¸‹æ–‡ç†è§£å¯¹è¯æƒ…å¢ƒå’Œäººç‰©å…³ç³»
2. å‡†ç¡®ä¼ è¾¾åŸæ„ã€è¯­æ°”å’Œæƒ…æ„Ÿ
3. ä½¿ç”¨æœ€è‡ªç„¶åœ°é“çš„{target_name}å£è¯­è¡¨è¾¾
4. é¿å…ä¹¦é¢è¯­å’Œç›´è¯‘è…”
5. ä¿æŒä¸ä¸Šä¸‹æ–‡çš„è¿è´¯æ€§
6. **é‡è¦ï¼šåªè¿”å›è¿™ä¸€å¥è¯çš„æ¶¦è‰²ç¿»è¯‘ï¼Œä¸è¦åˆ†æˆå¤šè¡Œï¼Œä¸è¦æ·»åŠ å…¶ä»–å¥å­**
7. ä¸è¦ä»»ä½•è§£é‡Šã€æ ‡ç‚¹ç¬¦å·æˆ–å¤šä½™å†…å®¹

æ¶¦è‰²åï¼š"""

        for attempt in range(max_retries):
            try:
                response = requests.post(
                    'https://api.deepseek.com/v1/chat/completions',
                    headers={
                        'Authorization': f'Bearer {self.deepseek_key}',
                        'Content-Type': 'application/json'
                    },
                    json={
                        'model': 'deepseek-chat',
                        'messages': [
                            {'role': 'system', 'content': f'ä½ æ˜¯ä¸“ä¸šçš„{target_name}å½±è§†å­—å¹•ç¿»è¯‘ä¸“å®¶ã€‚'},
                            {'role': 'user', 'content': prompt}
                        ],
                        'temperature': 0.5,
                        'max_tokens': 500
                    },
                    timeout=90
                )

                if response.status_code == 200:
                    result = response.json()
                    polished = result['choices'][0]['message']['content'].strip()

                    # å¦‚æœè¿”å›å¤šè¡Œï¼Œåªå–ç¬¬ä¸€è¡Œï¼ˆä¿®å¤DeepSeekå¯èƒ½è¿”å›å¤šè¡Œçš„é—®é¢˜ï¼‰
                    if '\n' in polished:
                        polished = polished.split('\n')[0].strip()

                    # æ¸…ç†å¯èƒ½çš„å¤šä½™å­—ç¬¦ï¼ˆå¦‚å¼€å¤´çš„"- "ç­‰ï¼‰
                    polished = polished.lstrip('- â€¢Â·').strip()

                    # æ¸…ç†å¼•å·
                    polished = polished.strip('"\'').strip()

                    # æœ€ç»ˆéªŒè¯ï¼šå¦‚æœç»“æœä¸ºç©ºæˆ–å¤ªçŸ­ï¼Œä½¿ç”¨åŸè¯‘æ–‡
                    if not polished or len(polished) < 2:
                        return translated

                    return polished
                else:
                    if attempt < max_retries - 1:
                        time.sleep(2)
                        continue
                    return translated
            except requests.exceptions.Timeout:
                if attempt < max_retries - 1:
                    time.sleep(2)
                else:
                    return translated
            except Exception as e:
                if attempt < max_retries - 1:
                    time.sleep(2)
                else:
                    return translated
        return translated

    def polish_batch_with_context(self, segments, source_lang, target_lang, step_idx=None, step_total=None):
        """æ‰¹é‡å¹¶å‘æ¶¦è‰²ï¼ˆå¸¦ä¸Šä¸‹æ–‡ï¼‰"""
        if not self.use_polish:
            return

        if step_idx and step_total:
            logging.info(f"  [{step_idx}/{step_total}] DeepSeekå¹¶å‘æ¶¦è‰²ï¼ˆ{self.concurrent_polish}çº¿ç¨‹ï¼‰...")
        else:
            logging.info(f"  DeepSeekå¹¶å‘æ¶¦è‰²ï¼ˆ{self.concurrent_polish}çº¿ç¨‹ï¼‰...")

        # æäº¤æ‰€æœ‰ä»»åŠ¡
        futures = {}
        for i, seg in enumerate(segments):
            context_before, context_after = self.get_context_window(segments, i, window_size=2)

            future = self.polish_executor.submit(
                self.polish_translation_with_context,
                seg['text'],
                seg['translated'],
                context_before,
                context_after,
                source_lang,
                target_lang
            )
            futures[future] = i

        # æ”¶é›†ç»“æœ
        completed = 0
        polish_examples = []  # è®°å½•æ¶¦è‰²ç¤ºä¾‹
        total = len(segments)

        for future in as_completed(futures):
            i = futures[future]
            try:
                polished = future.result(timeout=120)  # 2åˆ†é’Ÿè¶…æ—¶

                # è®°å½•å˜åŒ–ï¼ˆå‰3ä¸ªç¤ºä¾‹ï¼‰
                if polished != segments[i]['translated'] and len(polish_examples) < 3:
                    context_before, context_after = self.get_context_window(segments, i, 2)
                    polish_examples.append({
                        'index': i + 1,
                        'original': segments[i]['translated'],
                        'polished': polished,
                        'context_before': context_before,
                        'context_after': context_after
                    })

                segments[i]['translated'] = polished

            except Exception as e:
                # å¤±è´¥æ—¶ä¿æŒåŸè¯‘æ–‡
                pass

            completed += 1
            # æ¯å®Œæˆ20%æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
            if completed % max(1, total // 5) == 0 or completed == total:
                logging.info(f"    æ¶¦è‰²è¿›åº¦: {completed}/{total} ({completed * 100 // total}%)")

        if step_idx and step_total:
            logging.info(f"  [{step_idx}/{step_total}] å¹¶å‘æ¶¦è‰²å®Œæˆ âœ“")
        else:
            logging.info("  å¹¶å‘æ¶¦è‰²å®Œæˆ âœ“")

        # æ˜¾ç¤ºæ¶¦è‰²ç¤ºä¾‹
        if polish_examples:
            logging.info("")
            for example in polish_examples:
                if example['context_before']:
                    logging.info(f"    ä¸Šæ–‡: ...{example['context_before'][-1]}")
                logging.info(f"    [{example['index']}] åŸè¯‘: {example['original']}")
                logging.info(f"    [{example['index']}] æ¶¦è‰²: {example['polished']}")
                if example['context_after']:
                    logging.info(f"    ä¸‹æ–‡: {example['context_after'][0]}...")
                logging.info("")

    def format_time(self, seconds):
        """æ ¼å¼åŒ–æ—¶é—´ä¸ºSRTæ ¼å¼"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millis = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"

    @staticmethod
    def format_time_ass(seconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é—´ä¸º ASS æ—¶é—´æˆ³ï¼šH:MM:SS.CSï¼ˆCS=1/100ç§’ï¼‰"""
        try:
            total_cs = int(round(float(seconds) * 100.0))
        except Exception:
            total_cs = 0
        if total_cs < 0:
            total_cs = 0
        cs = total_cs % 100
        total_sec = total_cs // 100
        s = total_sec % 60
        m = (total_sec // 60) % 60
        h = total_sec // 3600
        return f"{h:d}:{m:02d}:{s:02d}.{cs:02d}"

    @staticmethod
    def _ass_escape(text: str) -> str:
        """ASS æ–‡æœ¬è½¬ä¹‰ï¼šæ¢è¡Œ->\\Nï¼Œé¿å…èŠ±æ‹¬å·è¢«å½“ä½œæ ·å¼æ ‡ç­¾ã€‚"""
        text = '' if text is None else str(text)
        text = text.replace('\r\n', '\n').replace('\r', '\n')
        text = text.replace('\n', r'\N')
        # èŠ±æ‹¬å·å¯èƒ½è§¦å‘ ASS override tagsï¼Œç›´æ¥æ›¿æ¢ä¸ºå…¨è§’ï¼Œé¿å…ç ´åæ ·å¼
        text = text.replace('{', 'ï½›').replace('}', 'ï½')
        return text

    @staticmethod
    def _probe_video_resolution(video_path: Path) -> tuple[int | None, int | None]:
        """ç”¨ ffprobe è·å–è§†é¢‘å®½é«˜ï¼›å¤±è´¥è¿”å› (None, None)ã€‚"""
        try:
            out = subprocess.check_output(
                [
                    'ffprobe',
                    '-v', 'error',
                    '-select_streams', 'v:0',
                    '-show_entries', 'stream=width,height',
                    '-of', 'json',
                    str(video_path),
                ],
                text=True,
                stderr=subprocess.DEVNULL,
            )
            data = json.loads(out) if out else {}
            streams = data.get('streams') or []
            if not streams:
                return None, None
            st = streams[0] or {}
            w = st.get('width')
            h = st.get('height')
            try:
                w = int(w) if w else None
            except Exception:
                w = None
            try:
                h = int(h) if h else None
            except Exception:
                h = None
            return w, h
        except Exception:
            return None, None

    def generate_srt(self, segments, output_path, translation_only=False):
        """ç”ŸæˆSRTå­—å¹•æ–‡ä»¶"""
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                for i, seg in enumerate(segments, 1):
                    start = self.format_time(seg['start'])
                    end = self.format_time(seg['end'])
                    text = seg['text']
                    translated = seg.get('translated', text)

                    f.write(f"{i}\n")
                    f.write(f"{start} --> {end}\n")

                    if translation_only:
                        f.write(f"{translated}\n\n")
                    else:
                        f.write(f"{text}\n")
                        f.write(f"{translated}\n\n")

            return True
        except Exception as e:
            logging.error(f"  Ã— ç”Ÿæˆå­—å¹•å¤±è´¥: {e}")
            return False

    def generate_ass(self, segments, output_path, translation_only=False, video_path: Path | None = None):
        """ç”Ÿæˆ ASS å­—å¹•æ–‡ä»¶ï¼ˆV4+ï¼‰ã€‚"""
        try:
            w, h = (None, None)
            if video_path is not None:
                w, h = self._probe_video_resolution(video_path)
            play_res_x = int(w or 1920)
            play_res_y = int(h or 1080)

            font_size = min(60, max(24, int(play_res_y * 0.06)))
            outline = max(2, int(font_size / 16))
            margin_v = max(20, int(font_size * 1.2))

            header = [
                "[Script Info]",
                "; Script generated by video-translation-service",
                "ScriptType: v4.00+",
                "Collisions: Normal",
                f"PlayResX: {play_res_x}",
                f"PlayResY: {play_res_y}",
                "WrapStyle: 2",
                "ScaledBorderAndShadow: yes",
                "",
                "[V4+ Styles]",
                "Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding",
                f"Style: Default,Noto Sans CJK SC,{font_size},&H00FFFFFF,&H000000FF,&H00000000,&H64000000,1,0,0,0,100,100,0,0,1,{outline},0,2,40,40,{margin_v},1",
                "",
                "[Events]",
                "Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text",
            ]

            with open(output_path, 'w', encoding='utf-8') as f:
                f.write("\n".join(header) + "\n")
                for seg in segments:
                    start = self.format_time_ass(seg.get('start', 0.0))
                    end = self.format_time_ass(seg.get('end', 0.0))
                    text = self._ass_escape(seg.get('text', ''))
                    translated = self._ass_escape(seg.get('translated', seg.get('text', '')))
                    if translation_only:
                        line = translated
                    else:
                        line = f"{text}\\N{translated}"
                    f.write(f"Dialogue: 0,{start},{end},Default,,0,0,0,,{line}\n")
            return True
        except Exception as e:
            logging.error(f"  Ã— ç”Ÿæˆå­—å¹•å¤±è´¥: {e}")
            return False

    def generate_subtitle_file(self, segments, output_path: Path, translation_only: bool, video_path: Path):
        fmt = (self.subtitle_format or 'srt').strip().lower()
        if fmt == 'ass':
            return self.generate_ass(segments, str(output_path), translation_only, video_path=video_path)
        return self.generate_srt(segments, str(output_path), translation_only)

    def translate_video(self, video_path, target_lang='zh', source_lang='auto',
                        translation_only=False, output_dir=None):
        """ç¿»è¯‘å•ä¸ªè§†é¢‘ï¼ˆå¸¦è¿›åº¦ç®¡ç†å’Œå¹¶å‘æ¶¦è‰²ï¼‰"""
        video_path = Path(video_path)
        video_name = video_path.name

        logging.info(f"\n{'=' * 70}")
        logging.info(f"å¤„ç†: {video_path.name}")
        logging.info(f"{'=' * 70}")

        # è¾“å‡ºè·¯å¾„
        if output_dir:
            output_dir = Path(output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)
        else:
            output_dir = video_path.parent

        fmt = (self.subtitle_format or 'srt').strip().lower()
        ext = '.ass' if fmt == 'ass' else '.srt'
        subtitle_path = output_dir / f"{video_path.stem}_{target_lang}{ext}"

        # æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡
        should_skip, reason = self.should_skip_video(video_path, subtitle_path)
        if should_skip:
            logging.info(f"  è·³è¿‡: {reason}")
            self.stats['skipped'] += 1
            return True
        elif reason:
            logging.info(f"  {reason}")

        # æ ‡è®°ä¸ºå¤„ç†ä¸­
        self.update_video_status(video_name, 'processing')

        temp_files = []
        try:
            start_time = time.time()

            total_steps = 4
            if self.enable_vocal_separation:
                total_steps += 1
            if self.use_polish:
                total_steps += 1

            step = 1

            # 1. æå–éŸ³é¢‘
            logging.info(f"  [{step}/{total_steps}] æå–éŸ³é¢‘...")
            audio_path = output_dir / f"{video_path.stem}_temp.wav"
            audio_sep_path = output_dir / f"{video_path.stem}_temp_sep.wav"
            vocals_path = output_dir / f"{video_path.stem}_temp_vocals.wav"

            if self.enable_vocal_separation:
                # Demucs å»ºè®®ä½¿ç”¨è¾ƒé«˜é‡‡æ ·ç‡/åŒå£°é“è¾“å…¥
                temp_files.append(audio_sep_path)
                if not self.extract_audio(str(video_path), str(audio_sep_path), sample_rate=44100, channels=2):
                    raise Exception("éŸ³é¢‘æå–å¤±è´¥")
            else:
                temp_files.append(audio_path)
                if not self.extract_audio(str(video_path), str(audio_path)):
                    raise Exception("éŸ³é¢‘æå–å¤±è´¥")
            logging.info(f"  [{step}/{total_steps}] æå–éŸ³é¢‘å®Œæˆ âœ“")

            # 2. äººå£°åˆ†ç¦»ï¼ˆå¯é€‰ï¼‰
            if self.enable_vocal_separation:
                step += 1
                self.clear_cuda_cache('before_vocal_separation')
                logging.info(f"  [{step}/{total_steps}] äººå£°åˆ†ç¦»ï¼ˆDemucsï¼Œå¯èƒ½è¾ƒæ…¢ï¼‰...")
                temp_files.append(vocals_path)
                self.separate_vocals(audio_sep_path, vocals_path)
                asr_audio_path = vocals_path
                logging.info(f"  [{step}/{total_steps}] äººå£°åˆ†ç¦»å®Œæˆ âœ“")
            else:
                asr_audio_path = audio_path

            # 3. è¯­éŸ³è¯†åˆ«
            step += 1
            self.clear_cuda_cache('before_asr')
            logging.info(f"  [{step}/{total_steps}] è¯­éŸ³è¯†åˆ«ï¼ˆé•¿è§†é¢‘å¯èƒ½éœ€è¦æ•°åˆ†é’Ÿï¼‰...")
            transcribe_start = time.time()
            asr_language = None if source_lang == 'auto' else source_lang
            if self.manage_models:
                # é¿å…ä¸ç¿»è¯‘æ¨¡å‹åŒæ—¶å ç”¨æ˜¾å­˜
                if self.unload_models_after_tasks:
                    self._service_models_unload(['translation'])
                if not self.ensure_models(want_asr=True):
                    raise Exception("ASRæ¨¡å‹åŠ è½½å¤±è´¥")
            result = self.transcribe(str(asr_audio_path), language=asr_language)

            # åˆ é™¤ä¸´æ—¶éŸ³é¢‘
            for temp_path in temp_files:
                try:
                    temp_path.unlink()
                except Exception:
                    pass

            if not result or not result.get('success'):
                raise Exception("è¯­éŸ³è¯†åˆ«å¤±è´¥")

            segments = result.get('segments', [])
            detected_lang = result.get('language', source_lang)
            transcribe_time = time.time() - transcribe_start
            logging.info(f"  [{step}/{total_steps}] è¯­éŸ³è¯†åˆ«å®Œæˆ âœ“ ({len(segments)}æ®µ, {transcribe_time:.1f}ç§’)")
            if self.manage_models and self.unload_models_after_tasks:
                self._service_models_unload(['asr'])

            # 4. ç¿»è¯‘ï¼ˆæ‰¹é‡ç¿»è¯‘ï¼‰
            step += 1
            translate_start = time.time()
            self.clear_cuda_cache('before_translation')
            logging.info(f"  [{step}/{total_steps}] ç¿»è¯‘ {len(segments)} æ®µ...")
            if self.manage_models:
                # ç¡®ä¿ ASR å·²é‡Šæ”¾ï¼ˆé¿å…ä¸ç¿»è¯‘æ¨¡å‹åŒæ—¶å ç”¨æ˜¾å­˜ï¼‰
                if self.unload_models_after_tasks:
                    self._service_models_unload(['asr'])
                if not self.ensure_models(want_translation=True):
                    raise Exception("ç¿»è¯‘æ¨¡å‹åŠ è½½å¤±è´¥")

            for i, seg in enumerate(segments, 1):
                translated = self.translate_text(
                    seg['text'],
                    detected_lang if source_lang == 'auto' else source_lang,
                    target_lang
                )
                seg['translated'] = translated

                # æ¯å®Œæˆ20%æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                if i % max(1, len(segments) // 5) == 0 or i == len(segments):
                    logging.info(f"    ç¿»è¯‘è¿›åº¦: {i}/{len(segments)} ({i * 100 // len(segments)}%)")

            logging.info(f"  [{step}/{total_steps}] ç¿»è¯‘å®Œæˆ âœ“")
            if self.manage_models and self.unload_models_after_tasks:
                self._service_models_unload(['translation'])

            # 5. å¹¶å‘æ¶¦è‰²ï¼ˆå¯é€‰ï¼‰
            if self.use_polish:
                step += 1
                self.polish_batch_with_context(
                    segments,
                    detected_lang if source_lang == 'auto' else source_lang,
                    target_lang,
                    step_idx=step,
                    step_total=total_steps
                )

            translate_time = time.time() - translate_start
            polish_suffix = f" (å«{self.concurrent_polish}çº¿ç¨‹å¹¶å‘æ¶¦è‰²)" if self.use_polish else ""

            # 6. ç”Ÿæˆå­—å¹•
            step += 1
            logging.info(f"  [{step}/{total_steps}] ç”Ÿæˆå­—å¹•...")
            if not self.generate_subtitle_file(segments, subtitle_path, translation_only, video_path):
                raise Exception("ç”Ÿæˆå­—å¹•å¤±è´¥")
            logging.info(f"  [{step}/{total_steps}] ç”Ÿæˆå­—å¹•å®Œæˆ âœ“")

            total_time = time.time() - start_time

            logging.info(f"\nâœ“ å®Œæˆ: {subtitle_path.name}")
            logging.info(f"  æ€»è€—æ—¶: {total_time:.1f}ç§’")
            logging.info(f"  è¯­éŸ³è¯†åˆ«: {transcribe_time:.1f}ç§’")
            logging.info(f"  ç¿»è¯‘+æ¶¦è‰²: {translate_time:.1f}ç§’{polish_suffix}")

            # æ ‡è®°ä¸ºå·²å®Œæˆ
            self.update_video_status(
                video_name,
                'completed',
                srt_file=str(subtitle_path.name),  # å…¼å®¹æ—§å­—æ®µå
                subtitle_file=str(subtitle_path.name),
                subtitle_format=fmt,
                duration=total_time
            )

            self.stats['success'] += 1
            return True

        except Exception as e:
            logging.error(f"\nÃ— å¤„ç†å¤±è´¥: {e}")

            # æ›´æ–°å¤±è´¥çŠ¶æ€
            retry_count = self.progress_data.get(video_name, {}).get('retry_count', 0)
            self.update_video_status(
                video_name,
                'failed',
                error=str(e),
                retry_count=retry_count + 1
            )

            self.stats['failed'] += 1
            return False
        finally:
            # å¤±è´¥æ—¶ä¹Ÿå°½é‡æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼Œé¿å…è¶…é•¿è§†é¢‘é—ç•™è¶…å¤§ WAV å ç”¨ç£ç›˜
            for temp_path in temp_files:
                try:
                    temp_path.unlink(missing_ok=True)
                except Exception:
                    pass

    def translate_directory(self, directory, target_lang='zh', source_lang='auto',
                            translation_only=False, recursive=False, output_dir=None):
        """æ‰¹é‡ç¿»è¯‘ç›®å½•ä¸­çš„è§†é¢‘ï¼ˆå¸¦è¿›åº¦ç®¡ç†ï¼‰"""
        directory = Path(directory)

        if not directory.exists():
            logging.error(f"Ã— ç›®å½•ä¸å­˜åœ¨: {directory}")
            return

        # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
        if recursive:
            video_files = []
            for ext in self.video_extensions:
                video_files.extend(directory.rglob(f"*{ext}"))
        else:
            video_files = []
            for ext in self.video_extensions:
                video_files.extend(directory.glob(f"*{ext}"))

        video_files = sorted(video_files)

        if not video_files:
            logging.error(f"Ã— æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶ï¼ˆæ”¯æŒæ ¼å¼: {', '.join(self.video_extensions)}ï¼‰")
            return

        # ç”Ÿæˆä»»åŠ¡åç§°
        task_name = directory.name.replace(' ', '_').replace('\\', '_').replace('/', '_')
        if not task_name:
            task_name = 'root'
        self.load_progress(task_name)

        self.stats['total'] = len(video_files)
        self.stats['start_time'] = time.time()

        logging.info(f"\n{'=' * 70}")
        logging.info(f"æ‰¹é‡ç¿»è¯‘ä»»åŠ¡: {task_name}")
        logging.info(f"{'=' * 70}")
        logging.info(f"ç›®å½•: {directory}")
        logging.info(f"è§†é¢‘æ•°é‡: {len(video_files)}")
        logging.info(f"ç›®æ ‡è¯­è¨€: {target_lang}")
        logging.info(f"å­—å¹•æ¨¡å¼: {'ä»…è¯‘æ–‡' if translation_only else 'åŒè¯­å­—å¹•'}")
        if self.use_polish:
            logging.info(f"DeepSeekæ¶¦è‰²: å¯ç”¨ï¼ˆ{self.concurrent_polish}çº¿ç¨‹å¹¶å‘ï¼‰")
        else:
            logging.info(f"DeepSeekæ¶¦è‰²: ç¦ç”¨")
        if self.enable_vocal_separation:
            logging.info(f"äººå£°åˆ†ç¦»: å¯ç”¨ï¼ˆDemucs {self.vocal_separation_model}, {self.vocal_separation_device}ï¼‰")
        else:
            logging.info("äººå£°åˆ†ç¦»: ç¦ç”¨")
        logging.info(f"{'=' * 70}")

        # å¤„ç†æ¯ä¸ªè§†é¢‘
        for i, video_file in enumerate(video_files, 1):
            logging.info(f"\n[{i}/{len(video_files)}]")

            try:
                self.translate_video(
                    video_file,
                    target_lang,
                    source_lang,
                    translation_only,
                    output_dir
                )
            except KeyboardInterrupt:
                logging.info("\n\nç”¨æˆ·ä¸­æ–­ - è¿›åº¦å·²ä¿å­˜ï¼Œä¸‹æ¬¡è¿è¡Œå°†ç»§ç»­")
                break
            except Exception as e:
                logging.error(f"Ã— æ„å¤–é”™è¯¯: {e}")
                continue

        self.stats['end_time'] = time.time()
        self.print_report()

    def print_report(self):
        """æ‰“å°å¤„ç†æŠ¥å‘Š"""
        if self.stats['start_time'] is None:
            return

        total_time = self.stats['end_time'] - self.stats['start_time']

        logging.info(f"\n{'=' * 70}")
        logging.info("å¤„ç†æŠ¥å‘Š")
        logging.info(f"{'=' * 70}")
        logging.info(f"æ€»è§†é¢‘æ•°: {self.stats['total']}")
        logging.info(f"æˆåŠŸ: {self.stats['success']}")
        logging.info(f"å¤±è´¥: {self.stats['failed']}")
        logging.info(f"è·³è¿‡: {self.stats['skipped']}")
        logging.info(f"æ€»è€—æ—¶: {total_time / 60:.1f}åˆ†é’Ÿ")

        if self.stats['success'] > 0:
            avg_time = total_time / self.stats['success']
            logging.info(f"å¹³å‡æ¯ä¸ª: {avg_time:.1f}ç§’")

        logging.info(f"{'=' * 70}")

    def show_progress(self, task_name):
        """æ˜¾ç¤ºè¿›åº¦"""
        self.load_progress(task_name)

        if not self.progress_data:
            logging.info("Ã— æ²¡æœ‰æ‰¾åˆ°è¿›åº¦è®°å½•")
            return

        completed = [k for k, v in self.progress_data.items() if v.get('status') == 'completed']
        failed = [k for k, v in self.progress_data.items() if v.get('status') == 'failed']
        processing = [k for k, v in self.progress_data.items() if v.get('status') == 'processing']

        logging.info(f"\n{'=' * 70}")
        logging.info(f"è¿›åº¦æŠ¥å‘Š: {task_name}")
        logging.info(f"{'=' * 70}")
        logging.info(f"å·²å®Œæˆ: {len(completed)}")
        logging.info(f"å·²å¤±è´¥: {len(failed)}")
        logging.info(f"å¤„ç†ä¸­: {len(processing)}")
        logging.info(f"æ€»è®¡: {len(self.progress_data)}")
        logging.info(f"{'=' * 70}")

        if failed:
            logging.info("\nå¤±è´¥åˆ—è¡¨:")
            for video in failed[:10]:
                error = self.progress_data[video].get('error', 'æœªçŸ¥é”™è¯¯')
                retry = self.progress_data[video].get('retry_count', 0)
                logging.info(f"  - {video}: {error} (é‡è¯•{retry}æ¬¡)")
            if len(failed) > 10:
                logging.info(f"  ... è¿˜æœ‰ {len(failed) - 10} ä¸ªå¤±è´¥")

    def reset_progress(self, task_name):
        """é‡ç½®è¿›åº¦"""
        progress_file = self.progress_dir / f'{task_name}.json'
        if progress_file.exists():
            progress_file.unlink()
            logging.info(f"âœ“ å·²æ¸…é™¤è¿›åº¦: {task_name}")
        else:
            logging.info(f"Ã— æ²¡æœ‰æ‰¾åˆ°è¿›åº¦æ–‡ä»¶: {task_name}")


def main():
    parser = argparse.ArgumentParser(
        description='æ‰¹é‡è§†é¢‘ç¿»è¯‘å·¥å…· v3.1 - å¹¶å‘æ¶¦è‰²ã€ä¸Šä¸‹æ–‡ç¿»è¯‘ã€æ–­ç‚¹ç»­ä¼ ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # ç¿»è¯‘å•ä¸ªè§†é¢‘ï¼ˆ10çº¿ç¨‹å¹¶å‘æ¶¦è‰²ï¼‰
  python batch_translate.py video.mp4 -t zh

  # æ‰¹é‡ç¿»è¯‘ï¼ˆè‡ªåŠ¨æ–­ç‚¹ç»­ä¼ ï¼‰
  python batch_translate.py videos/ -t zh

  # è‡ªå®šä¹‰å¹¶å‘æ•°ï¼ˆ20çº¿ç¨‹ï¼‰
  python batch_translate.py videos/ -t zh --concurrent 20

  # æŸ¥çœ‹è¿›åº¦
  python batch_translate.py videos/ --show-progress
        """
    )

    parser.add_argument('input', help='è§†é¢‘æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„')
    parser.add_argument('-t', '--target', default='zh', help='ç›®æ ‡è¯­è¨€ï¼ˆé»˜è®¤: zhï¼‰')
    parser.add_argument('-s', '--source', default=None, help='æºè¯­è¨€/ASRè¯­è¨€ï¼ˆé»˜è®¤: è¯»å–config.iniï¼›æœªé…ç½®åˆ™autoè‡ªåŠ¨æ£€æµ‹ï¼‰')
    parser.add_argument('-o', '--output', help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: ä¸è§†é¢‘åŒç›®å½•ï¼‰')
    parser.add_argument('--translation-only', action='store_true', help='ä»…ç”Ÿæˆè¯‘æ–‡å­—å¹•ï¼ˆä¸å«åŸæ–‡ï¼‰')
    parser.add_argument('--recursive', '-r', action='store_true', help='é€’å½’å¤„ç†å­ç›®å½•')
    parser.add_argument('--polish', action='store_true', help='ä½¿ç”¨DeepSeekæ¶¦è‰²ç¿»è¯‘')
    parser.add_argument('--concurrent', type=int, default=10, help='DeepSeekå¹¶å‘æ•°ï¼ˆé»˜è®¤: 10ï¼‰')
    parser.add_argument('--deepseek-key', help='DeepSeek APIå¯†é’¥')
    parser.add_argument('--service-url', default='http://127.0.0.1:50515',
                        help='ç¿»è¯‘æœåŠ¡åœ°å€ï¼ˆé»˜è®¤: http://127.0.0.1:50515ï¼‰')
    parser.add_argument('--vocal-separation', action='store_true', default=None,
                        help='å¯ç”¨äººå£°åˆ†ç¦»ï¼ˆDemucsï¼Œç”¨äºèƒŒæ™¯éŸ³ä¹/å˜ˆæ‚åœºæ™¯ï¼›éœ€è¦ pip install demucsï¼‰')
    parser.add_argument('--vocal-model', default=None,
                        help='Demucs æ¨¡å‹åï¼ˆé»˜è®¤: è¯»å–config.ini æˆ– htdemucsï¼‰')
    parser.add_argument('--vocal-device', default=None, choices=['auto', 'cpu', 'cuda'],
                        help='äººå£°åˆ†ç¦»è®¾å¤‡ï¼šauto/cpu/cudaï¼ˆé»˜è®¤: è¯»å–config.ini æˆ– autoï¼‰')
    parser.add_argument('--vocal-chunk-sec', type=int, default=None,
                        help='Demucs åˆ†æ®µç§’æ•°ï¼ˆä»…è¶…é•¿/è¶…å¤§éŸ³é¢‘è§¦å‘ï¼›é»˜è®¤è¯»å–config.iniï¼›é»˜è®¤1800ï¼‰')
    parser.add_argument('--cuda-clear', dest='cuda_clear', action='store_true', default=None,
                        help='åœ¨GPUé‡ä»»åŠ¡å‰æ¸…ç†CUDAç¼“å­˜ï¼ˆé™ä½OOMæ¦‚ç‡ï¼Œç•¥æ…¢ï¼‰')
    parser.add_argument('--no-cuda-clear', dest='cuda_clear', action='store_false',
                        help='ç¦ç”¨GPUä»»åŠ¡å‰æ¸…ç†CUDAç¼“å­˜')
    parser.add_argument('--asr-chunk-sec', type=int, default=None,
                        help='ASR åˆ†å—ç§’æ•°ï¼ˆå¯ç”¨è¿›åº¦æ¡/é™ä½é•¿éŸ³é¢‘500/OOMï¼›0=ç¦ç”¨ï¼›é»˜è®¤è¯»å–config.iniï¼‰')
    parser.add_argument('--asr-overlap-sec', type=float, default=None,
                        help='ASR åˆ†å—é‡å ç§’æ•°ï¼ˆé¿å…åˆ‡åœ¨å•è¯ä¸­é—´ï¼›é»˜è®¤è¯»å–config.iniï¼‰')
    parser.add_argument('--manage-models', dest='manage_models', action='store_true', default=None,
                        help='æŒ‰éœ€åŠ è½½/å¸è½½æœåŠ¡ç«¯æ¨¡å‹ï¼ˆé€‚åˆæ˜¾å­˜ç´§å¼ ç¯å¢ƒï¼Œå¦‚ Colab T4ï¼‰')
    parser.add_argument('--no-manage-models', dest='manage_models', action='store_false',
                        help='ç¦ç”¨æŒ‰éœ€åŠ è½½/å¸è½½æœåŠ¡ç«¯æ¨¡å‹')
    parser.add_argument('--unload-models', dest='unload_models', action='store_true', default=None,
                        help='åœ¨ ASR/ç¿»è¯‘å®Œæˆåå¸è½½æœåŠ¡ç«¯æ¨¡å‹é‡Šæ”¾æ˜¾å­˜ï¼ˆéœ€è¦ --manage-models æˆ– config.iniï¼‰')
    parser.add_argument('--no-unload-models', dest='unload_models', action='store_false',
                        help='ä¸åœ¨ä»»åŠ¡åå¸è½½æ¨¡å‹')
    parser.add_argument('--model-load-timeout', type=int, default=None,
                        help='ç­‰å¾…æœåŠ¡ç«¯æ¨¡å‹åŠ è½½è¶…æ—¶ç§’æ•°ï¼ˆé»˜è®¤è¯»å–config.iniæˆ–3600ï¼‰')
    parser.add_argument('--wait-ready', action='store_true',
                        help='ç­‰å¾…ç¿»è¯‘æœåŠ¡å°±ç»ªï¼ˆé¦–æ¬¡ä¸‹è½½/åŠ è½½æ¨¡å‹å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼‰')
    parser.add_argument('--wait-timeout', type=int, default=3600,
                        help='ç­‰å¾…ç¿»è¯‘æœåŠ¡å°±ç»ªè¶…æ—¶ç§’æ•°ï¼ˆé»˜è®¤: 3600ï¼‰')
    parser.add_argument('--show-progress', action='store_true', help='æ˜¾ç¤ºå½“å‰è¿›åº¦')
    parser.add_argument('--reset-progress', action='store_true', help='æ¸…é™¤è¿›åº¦è®°å½•ï¼Œä»å¤´å¼€å§‹')
    parser.add_argument('--subtitle-format', choices=['srt', 'ass'], default=None,
                        help='å­—å¹•æ ¼å¼ï¼šsrt/assï¼ˆé»˜è®¤è¯»å–config.iniï¼›æœªé…ç½®åˆ™srtï¼‰')

    args = parser.parse_args()

    # æ£€æŸ¥è¾“å…¥
    input_path = Path(args.input)
    if not input_path.exists():
        print(f"Ã— è·¯å¾„ä¸å­˜åœ¨: {args.input}")
        return 1

    # ç”Ÿæˆä»»åŠ¡åç§°
    if input_path.is_dir():
        task_name = input_path.name.replace(' ', '_').replace('\\', '_').replace('/', '_')
        if not task_name:
            task_name = 'root'
    else:
        task_name = input_path.parent.name.replace(' ', '_').replace('\\', '_').replace('/', '_')
        if not task_name:
            task_name = 'root'

    # ç¡®å®šæ˜¯å¦ä½¿ç”¨æ¶¦è‰²
    use_polish = args.polish
    if not use_polish and CONFIG_AVAILABLE:
        use_polish = config.use_deepseek_polish

    # æºè¯­è¨€ï¼ˆå‘½ä»¤è¡Œ > config.ini > autoï¼‰
    if args.source:
        source_lang = args.source
    elif CONFIG_AVAILABLE:
        source_lang = getattr(config, 'asr_language', None) or 'auto'
    else:
        source_lang = 'auto'

    # ç¡®å®šæ˜¯å¦å¯ç”¨äººå£°åˆ†ç¦»ï¼ˆå‘½ä»¤è¡Œ > config.iniï¼‰
    if args.vocal_separation is None:
        enable_vocal_separation = config.enable_vocal_separation if CONFIG_AVAILABLE else False
    else:
        enable_vocal_separation = bool(args.vocal_separation)

    vocal_separation_model = args.vocal_model
    if not vocal_separation_model and CONFIG_AVAILABLE:
        vocal_separation_model = config.vocal_separation_model
    if not vocal_separation_model:
        vocal_separation_model = 'htdemucs'

    vocal_separation_device = args.vocal_device
    if not vocal_separation_device and CONFIG_AVAILABLE:
        vocal_separation_device = config.vocal_separation_device
    if not vocal_separation_device:
        vocal_separation_device = 'auto'

    # Demucs åˆ†æ®µç§’æ•°ï¼ˆå‘½ä»¤è¡Œ > config.ini > 1800ï¼‰
    if args.vocal_chunk_sec is None:
        vocal_separation_chunk_sec = config.vocal_separation_chunk_sec if CONFIG_AVAILABLE else 1800
    else:
        vocal_separation_chunk_sec = int(args.vocal_chunk_sec)
    if vocal_separation_chunk_sec <= 0:
        vocal_separation_chunk_sec = 1800

    # æ˜¯å¦åœ¨ GPU é‡ä»»åŠ¡å‰æ¸…ç† CUDA ç¼“å­˜ï¼ˆå‘½ä»¤è¡Œ > config.iniï¼‰
    if args.cuda_clear is None:
        clear_cuda_cache_before_tasks = config.clear_cuda_cache_before_tasks if CONFIG_AVAILABLE else False
    else:
        clear_cuda_cache_before_tasks = bool(args.cuda_clear)

    # ASR åˆ†å—ï¼ˆå‘½ä»¤è¡Œ > config.iniï¼‰
    if args.asr_chunk_sec is None:
        asr_chunk_sec = config.asr_chunk_sec if CONFIG_AVAILABLE else 0
    else:
        asr_chunk_sec = int(args.asr_chunk_sec)

    if args.asr_overlap_sec is None:
        asr_chunk_overlap_sec = config.asr_chunk_overlap_sec if CONFIG_AVAILABLE else 0.0
    else:
        asr_chunk_overlap_sec = float(args.asr_overlap_sec)

    # æŒ‰éœ€åŠ è½½/å¸è½½æœåŠ¡ç«¯æ¨¡å‹ï¼ˆå‘½ä»¤è¡Œ > config.iniï¼‰
    if args.manage_models is None:
        manage_models = config.manage_models if CONFIG_AVAILABLE else False
    else:
        manage_models = bool(args.manage_models)

    if args.unload_models is None:
        unload_models_after_tasks = config.unload_models_after_tasks if CONFIG_AVAILABLE else False
    else:
        unload_models_after_tasks = bool(args.unload_models)

    if unload_models_after_tasks:
        manage_models = True

    if args.model_load_timeout is None:
        model_load_timeout = 3600
    else:
        model_load_timeout = int(args.model_load_timeout)

    # å­—å¹•æ ¼å¼ï¼ˆå‘½ä»¤è¡Œ > config.ini > srtï¼‰
    if args.subtitle_format:
        subtitle_format = (args.subtitle_format or 'srt').strip().lower()
    elif CONFIG_AVAILABLE:
        subtitle_format = getattr(config, 'subtitle_format', 'srt') or 'srt'
    else:
        subtitle_format = 'srt'

    # åˆ›å»ºç¿»è¯‘å™¨
    translator = VideoTranslator(
        service_url=args.service_url,
        deepseek_key=args.deepseek_key,
        use_polish=use_polish,
        concurrent_polish=args.concurrent,
        enable_vocal_separation=enable_vocal_separation,
        vocal_separation_model=vocal_separation_model,
        vocal_separation_device=vocal_separation_device,
        vocal_separation_chunk_sec=vocal_separation_chunk_sec,
        clear_cuda_cache_before_tasks=clear_cuda_cache_before_tasks,
        asr_chunk_sec=asr_chunk_sec,
        asr_chunk_overlap_sec=asr_chunk_overlap_sec,
        manage_models=manage_models,
        unload_models_after_tasks=unload_models_after_tasks,
        model_load_timeout=model_load_timeout,
        subtitle_format=subtitle_format,
    )

    # å¤„ç†è¿›åº¦å‘½ä»¤
    if args.show_progress:
        translator.show_progress(task_name)
        return 0

    if args.reset_progress:
        translator.reset_progress(task_name)
        if not input_path.exists():
            return 0

    # è®¾ç½®æ—¥å¿—ç³»ç»Ÿ
    log_file = setup_logger()
    logging.info(f"æ—¥å¿—æ–‡ä»¶: {log_file}")
    logging.info(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logging.info("")

    # è‡ªåŠ¨æ¸…ç†æ—§æ—¥å¿—ï¼ˆå¦‚æœé…ç½®å¯ç”¨ï¼‰
    if CONFIG_AVAILABLE:
        auto_cleanup = getattr(config, 'auto_cleanup_logs', False)
        keep_days = getattr(config, 'log_keep_days', 7)
    else:
        auto_cleanup = os.getenv('AUTO_CLEANUP_LOGS', '').lower() in ('true', '1', 'yes')
        keep_days = int(os.getenv('LOG_KEEP_DAYS', '7'))

    if auto_cleanup:
        cleanup_old_logs('log', keep_days, auto_cleanup)

    # æ£€æŸ¥æœåŠ¡
    if not translator.check_service(wait_ready=args.wait_ready, wait_timeout=args.wait_timeout):
        return 1

    # æ£€æŸ¥äººå£°åˆ†ç¦»ä¾èµ–
    if enable_vocal_separation:
        try:
            import demucs  # noqa: F401
        except Exception:
            logging.error("Ã— å·²å¯ç”¨äººå£°åˆ†ç¦»ï¼Œä½†æœªå®‰è£… demucs")
            logging.error("  è¯·è¿è¡Œ: pip install demucs")
            return 1

    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    if use_polish or args.polish:
        if translator.deepseek_key:
            logging.info(f"âœ“ DeepSeek APIå¯†é’¥å·²é…ç½®")
            if translator.use_polish:
                logging.info(f"âœ“ DeepSeekå¹¶å‘æ¶¦è‰²å·²å¯ç”¨ï¼ˆ{args.concurrent}çº¿ç¨‹ï¼‰")
        else:
            logging.error("Ã— DeepSeek APIå¯†é’¥æœªé…ç½®")

    # æ£€æŸ¥DeepSeeké…ç½®
    if (args.polish or use_polish) and not translator.deepseek_key:
        logging.error("Ã— å¯ç”¨æ¶¦è‰²åŠŸèƒ½éœ€è¦DeepSeek APIå¯†é’¥")
        logging.error("  æ–¹æ³•1: åœ¨ config.ini ä¸­é…ç½® [API] deepseek_api_key")
        logging.error("  æ–¹æ³•2: è®¾ç½®ç¯å¢ƒå˜é‡ set DEEPSEEK_API_KEY=your_key")
        logging.error("  æ–¹æ³•3: ä½¿ç”¨å‚æ•° --deepseek-key your_key")
        return 1

    logging.info("")

    # å¼€å§‹å¤„ç†
    try:
        if input_path.is_file():
            # å•ä¸ªè§†é¢‘
            translator.load_progress(task_name)
            translator.stats['total'] = 1
            translator.stats['start_time'] = time.time()

            translator.translate_video(
                input_path,
                args.target,
                source_lang,
                args.translation_only,
                args.output
            )

            translator.stats['end_time'] = time.time()
            translator.print_report()
        else:
            # ç›®å½•æ‰¹é‡å¤„ç†
            translator.translate_directory(
                input_path,
                args.target,
                source_lang,
                args.translation_only,
                args.recursive,
                args.output
            )
    except KeyboardInterrupt:
        logging.info("\n\nç”¨æˆ·ä¸­æ–­")
        return 1

    logging.info(f"\nç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logging.info(f"æ—¥å¿—å·²ä¿å­˜åˆ°: {log_file}")

    return 0


if __name__ == '__main__':
    sys.exit(main())
