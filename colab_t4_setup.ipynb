{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3dd3480",
   "metadata": {},
   "source": [
    "# video-translation-service（Colab + T4 GPU）一键安装运行\n",
    "\n",
    "目标：从直链下载 `1.mp4` → 生成中文字幕 `1_zh.ass`（不启用润色）。\n",
    "\n",
    "注意：首次运行会下载 Whisper + 翻译模型（可能几 GB），需要等待一段时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533131a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接把你的直链贴到这里即可\n",
    "VIDEO_URL = \"https://xxx.com/d/存储/1.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a57f1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 0) 确认已启用 GPU（Runtime -> Change runtime type -> GPU -> T4）\n",
    "!nvidia-smi -L\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "print(\"python:\", sys.version)\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"cuda_available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"gpu:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    raise RuntimeError(\"未检测到GPU：请在 Colab 切换到 GPU(T4) 运行时\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335f0d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1) git clone 项目\n",
    "# TODO: 改成你的仓库地址（私有仓库可用：https://<TOKEN>@github.com/<org>/<repo>.git）\n",
    "REPO_URL = \"https://github.com/MAE5blog/video-translation-service.git\"\n",
    "BRANCH = \"main\"\n",
    "REPO_DIR = \"/content/video-translation-service\"\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "if os.path.exists(REPO_DIR):\n",
    "    shutil.rmtree(REPO_DIR)\n",
    "\n",
    "!git clone --depth 1 -b {BRANCH} {REPO_URL} {REPO_DIR}\n",
    "%cd {REPO_DIR}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971c8d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 2) 安装系统依赖（ffmpeg + 字体）\n",
    "!apt-get update -y\n",
    "!apt-get install -y ffmpeg fonts-noto-cjk libsndfile1 build-essential cmake ninja-build\n",
    "!ffmpeg -version | head -n 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb8afd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3) 安装 Python 依赖\n",
    "# 说明：Colab 自带 CUDA 版 torch，避免从 requirements.txt 里重复安装 torch（否则可能被换成CPU版/或耗时升级）\n",
    "!python -m pip install -U pip\n",
    "!grep -vE '^torch' requirements.txt > /tmp/requirements_no_torch.txt\n",
    "!python -m pip install -r /tmp/requirements_no_torch.txt\n",
    "\n",
    "# 可选：人声分离（Demucs）用于嘈杂/背景音乐场景\n",
    "!python -m pip install demucs\n",
    "\n",
    "# torchaudio 新版本保存音频需要 torchcodec（否则 Demucs 会报错）\n",
    "!python -m pip install torchcodec\n",
    "\n",
    "# OpenList/AList 大文件上传：requests 默认 multipart 会把文件读进内存，需用 requests-toolbelt 流式上传\n",
    "!python -m pip install requests-toolbelt\n",
    "\n",
    "# 预编译 llama-cpp-python wheel（可复用，优先下载）\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "\n",
    "LLAMA_WHEEL_URL = \"https://oplist.mae5.com/d/gdrive_lz26xg/share/llama_cpp_python-0.3.16-cp312-cp312-linux_x86_64.whl?sign=s08ZZHeakHFTTevv8Vja5I-6HPXyT4ojOHMesEXpZUQ=:0\"\n",
    "LLAMA_WHEEL_DIR = Path(\"/content/llama_wheels\")\n",
    "LLAMA_WHEEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LLAMA_WHEEL_PATH = LLAMA_WHEEL_DIR / \"llama_cpp_python-0.3.16-cp312-cp312-linux_x86_64.whl\"\n",
    "if not LLAMA_WHEEL_PATH.exists():\n",
    "    try:\n",
    "        print(\"Downloading prebuilt llama-cpp-python wheel ...\")\n",
    "        urllib.request.urlretrieve(LLAMA_WHEEL_URL, LLAMA_WHEEL_PATH)\n",
    "    except Exception as e:\n",
    "        print(\"Prebuilt wheel download failed, will build from source:\", e)\n",
    "# GGUF/llama.cpp 翻译（默认模型为 GGUF 时需要，CPU 也可用）\n",
    "# wheel 会保存在 /content/llama_wheels，便于上传复用\n",
    "!bash -lc 'LLAMA_WHEEL_DIR=/content/llama_wheels; mkdir -p \"$LLAMA_WHEEL_DIR\"; if ls \"$LLAMA_WHEEL_DIR\"/llama_cpp_python-*.whl >/dev/null 2>&1; then python -m pip install \"$LLAMA_WHEEL_DIR\"/llama_cpp_python-*.whl; else MAX_JOBS=2 CMAKE_ARGS=\"-DGGML_CUDA=on -DCMAKE_CUDA_ARCHITECTURES=75\" FORCE_CMAKE=1 python -m pip wheel llama-cpp-python -w \"$LLAMA_WHEEL_DIR\" -v; python -m pip install \"$LLAMA_WHEEL_DIR\"/llama_cpp_python-*.whl; fi'\n",
    "# 如果编译失败，可改用 CPU 版：!python -m pip install llama-cpp-python --no-cache-dir -v\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f80973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4) 生成 config.ini（GPU + 中文 + 不润色）\n",
    "from pathlib import Path\n",
    "\n",
    "# 分块识别开关（默认关闭）\n",
    "# 说明：分块越小，越容易把单词/句子切开；但分块越大，越容易触发服务端 500/OOM。\n",
    "# 建议从 900s（15分钟）起步，不稳定再降到 600/300。\n",
    "ENABLE_ASR_CHUNKING = False  # True=分块识别（显示进度条/降低长音频500/OOM）\n",
    "ASR_CHUNK_SEC = 900\n",
    "ASR_CHUNK_OVERLAP_SEC = 1.0\n",
    "\n",
    "# ReazonSpeech/transformers 内部分块（仅对 transformers 后端生效）\n",
    "# 默认 30s/5s 可显著降低长音频 OOM/掉线风险；如稳定可调大或设 0 禁用\n",
    "ASR_TRANSFORMERS_CHUNK_SEC = 90\n",
    "ASR_TRANSFORMERS_STRIDE_SEC = 5.0\n",
    "\n",
    "# Demucs 人声分离分段秒数（仅对超长/超大音频触发；越大越不容易出现边界接缝，但越吃内存）\n",
    "# 如果仍然 OOM，可降到 600/300；如果视频特别长但内存足够，可升到 3600。\n",
    "DEMUCS_CHUNK_SEC = 1800\n",
    "\n",
    "# 人声+混音融合比例（0=仅人声；0.2=加入20%原始混音，减少漏词/空洞）\n",
    "# 建议范围：0.1 ~ 0.4；越大越接近原音（噪声也会更多）\n",
    "VOCAL_MIX_RATIO = 0.2\n",
    "\n",
    "# 指定 ASR 音频语言（auto=自动检测；填错会变差）\n",
    "# 备选示例：auto / en / zh / ja / ko / de / fr / es / ru / ar\n",
    "ASR_LANGUAGE = \"ja\"\n",
    "\n",
    "# ASR 回退到原始混音（人声分离出现长空洞/提前结束时）\n",
    "ASR_FALLBACK_TO_MIX = True\n",
    "# 触发阈值：最大空洞 / 末尾缺失（秒）\n",
    "ASR_FALLBACK_MAX_GAP_SEC = 45\n",
    "ASR_FALLBACK_END_DIFF_SEC = 60\n",
    "\n",
    "# ASR 模型：默认 reazonspeech（日语优化，transformers 后端）\n",
    "# 其它语言可改为 medium / large-v3；或自定义：reazonspeech:HF模型名\n",
    "ASR_MODEL_SIZE = \"reazonspeech\"\n",
    "\n",
    "# 字幕时间轴修复（避免长静音字幕滞留；参数太激进可能导致字幕提前结束）\n",
    "# 一般无需改动；若字幕提前结束：先把 SUBTITLE_LINGER_KEEP_RATIO 调大（例如 6），或直接 SUBTITLE_FIX_LINGER=False。\n",
    "SUBTITLE_FORMAT = \"ass\"  # 字幕格式：srt / ass（推荐 ass）\n",
    "SUBTITLE_FIX_LINGER = True  # True=启用“滞留修复”；False=完全按 ASR 原始时间轴输出\n",
    "SUBTITLE_MIN_DURATION_SEC = 1.2  # 单条字幕最短显示秒数（避免一闪而过）\n",
    "SUBTITLE_MAX_DURATION_SEC = 20.0  # 单条字幕最长显示秒数（用于限制长静音滞留）\n",
    "SUBTITLE_CHARS_PER_SEC = 5.0  # 阅读速度估算：每秒字符数（越大越快->字幕更短）\n",
    "SUBTITLE_LINGER_SLACK_SEC = 0.8  # 容忍额外时长（秒），减少误判\n",
    "SUBTITLE_LINGER_TRIGGER_SEC = 10.0  # 仅当原始持续时间>=该值才考虑收缩\n",
    "SUBTITLE_LINGER_TRIGGER_RATIO = 6.0  # 仅当 原始时长 > 可读时长*ratio 才触发（越大越不容易触发）\n",
    "SUBTITLE_LINGER_KEEP_RATIO = 4.0  # 触发后保留：可读时长*ratio（越大越不容易提前结束）\n",
    "\n",
    "config_text = f\"\"\"[API]\n",
    "deepseek_api_key =\n",
    "\n",
    "[Service]\n",
    "host = 127.0.0.1\n",
    "port = 50515\n",
    "lazy_load_models = true\n",
    "manage_models = true\n",
    "unload_models_after_tasks = true\n",
    "\n",
    "[Models]\n",
    "# 如果显存不够/加载太慢，可改：asr_model_size = small\n",
    "asr_model_size = {ASR_MODEL_SIZE}\n",
    "\n",
    "# 翻译模型：默认使用 GGUF 量化（T4 更稳）；如显存不够可改为 nllb-200-distilled-1.3B；GGUF 用法：gguf:/path/to/model.gguf（需安装 llama-cpp-python）\n",
    "translation_model = gguf:hf:SakuraLLM/Sakura-7B-Qwen2.5-v1.0-GGUF@sakura-7b-qwen2.5-v1.0-iq4xs.gguf\n",
    "\n",
    "use_gpu = true\n",
    "beam_size = 5\n",
    "\n",
    "[GPU]\n",
    "# 在 GPU 重任务前清理 CUDA 缓存，降低 OOM 概率（略慢）\n",
    "clear_cuda_cache_before_tasks = true\n",
    "\n",
    "[ASR]\n",
    "# 指定音频语言（可提升嘈杂场景稳定性；填错会变差）\n",
    "language = {ASR_LANGUAGE}\n",
    "\n",
    "# 分块识别：显示进度条，也可降低长音频导致的 500/OOM\n",
    "chunk_sec = {ASR_CHUNK_SEC if ENABLE_ASR_CHUNKING else 0}\n",
    "# 重叠一点点，避免切在单词中间（会产生少量重复，程序会尽量去重）\n",
    "chunk_overlap_sec = {ASR_CHUNK_OVERLAP_SEC}\n",
    "\n",
    "# transformers 内部分块（仅对 reazonspeech/transformers 后端生效）\n",
    "transformers_chunk_sec = {ASR_TRANSFORMERS_CHUNK_SEC}\n",
    "transformers_stride_sec = {ASR_TRANSFORMERS_STRIDE_SEC}\n",
    "\n",
    "# 人声分离回退：检测到长空洞/末尾缺失时，改用原始混音识别\n",
    "fallback_to_mix = {str(ASR_FALLBACK_TO_MIX).lower()}\n",
    "fallback_max_gap_sec = {ASR_FALLBACK_MAX_GAP_SEC}\n",
    "fallback_end_diff_sec = {ASR_FALLBACK_END_DIFF_SEC}\n",
    "\n",
    "[Translation]\n",
    "default_target_language = zh\n",
    "use_deepseek_polish = false\n",
    "\n",
    "[Subtitles]\n",
    "format = {SUBTITLE_FORMAT}\n",
    "fix_linger = {str(SUBTITLE_FIX_LINGER).lower()}\n",
    "min_duration_sec = {SUBTITLE_MIN_DURATION_SEC}\n",
    "max_duration_sec = {SUBTITLE_MAX_DURATION_SEC}\n",
    "chars_per_sec = {SUBTITLE_CHARS_PER_SEC}\n",
    "linger_slack_sec = {SUBTITLE_LINGER_SLACK_SEC}\n",
    "linger_trigger_sec = {SUBTITLE_LINGER_TRIGGER_SEC}\n",
    "linger_trigger_ratio = {SUBTITLE_LINGER_TRIGGER_RATIO}\n",
    "linger_keep_ratio = {SUBTITLE_LINGER_KEEP_RATIO}\n",
    "\n",
    "[Audio]\n",
    "# 人声分离（Demucs）：改善背景音乐/嘈杂场景识别\n",
    "enable_vocal_separation = true\n",
    "vocal_separation_model = htdemucs\n",
    "# 默认用 cuda 加速；如遇 OOM 可改为 cpu\n",
    "vocal_separation_device = cuda\n",
    "vocal_separation_chunk_sec = {DEMUCS_CHUNK_SEC}\n",
    "vocal_mix_ratio = {VOCAL_MIX_RATIO}\n",
    "\"\"\"\n",
    "\n",
    "Path(\"config.ini\").write_text(config_text, encoding=\"utf-8\")\n",
    "print(\"wrote config.ini\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3aebfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 5) 后台启动服务（不占用单元格）\n",
    "import os\n",
    "import pathlib\n",
    "import signal\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import requests\n",
    "\n",
    "SERVICE_URL = \"http://127.0.0.1:50515\"\n",
    "FORCE_RESTART = False  # True=重启服务并生成 server.log（用于排查 500）\n",
    "RETURN_TRACEBACK = False  # True=服务端 500 时返回 JSON traceback（更容易定位问题）\n",
    "\n",
    "def health():\n",
    "    try:\n",
    "        return requests.get(f\"{SERVICE_URL}/health\", timeout=2).json()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def stop_running_server():\n",
    "    pid_path = pathlib.Path(\"server.pid\")\n",
    "    if pid_path.exists():\n",
    "        try:\n",
    "            pid = int(pid_path.read_text().strip())\n",
    "            os.kill(pid, signal.SIGTERM)\n",
    "            print(\"killed by server.pid:\", pid)\n",
    "        except Exception as e:\n",
    "            print(\"failed to kill by server.pid:\", e)\n",
    "\n",
    "    # 兜底：按端口杀（Colab/Linux）\n",
    "    subprocess.run([\"bash\", \"-lc\", \"fuser -k 50515/tcp || true\"], check=False)\n",
    "\n",
    "h = health()\n",
    "if h and FORCE_RESTART:\n",
    "    print(\"force restart: stopping existing server ...\")\n",
    "    stop_running_server()\n",
    "    time.sleep(2)\n",
    "    h = health()\n",
    "\n",
    "if not h:\n",
    "    env = os.environ.copy()\n",
    "    if RETURN_TRACEBACK:\n",
    "        env[\"VTS_RETURN_TRACEBACK\"] = \"1\"\n",
    "    p = subprocess.Popen(\n",
    "        [sys.executable, \"server_optimized.py\"],\n",
    "        stdout=open(\"server.log\", \"wb\"),\n",
    "        stderr=subprocess.STDOUT,\n",
    "        start_new_session=True,\n",
    "        env=env,\n",
    "    )\n",
    "    pathlib.Path(\"server.pid\").write_text(str(p.pid))\n",
    "    print(\"server started, pid:\", p.pid)\n",
    "else:\n",
    "    print(\"server already running:\", h)\n",
    "    if not pathlib.Path(\"server.log\").exists():\n",
    "        print(\"NOTE: 未找到 server.log；如需抓取服务端报错，请将 FORCE_RESTART=True 再运行本单元格。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836426f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 6) 等待服务启动（模型按需加载）\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "\n",
    "SERVICE_URL = \"http://127.0.0.1:50515\"\n",
    "pid_path = Path(\"server.pid\")\n",
    "log_path = Path(\"server.log\")\n",
    "\n",
    "def pid_alive(pid: int) -> bool:\n",
    "    try:\n",
    "        os.kill(pid, 0)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def tail_log(max_lines: int = 120) -> str:\n",
    "    if not log_path.exists():\n",
    "        return \"(server.log not found)\"\n",
    "    try:\n",
    "        lines = log_path.read_text(errors=\"ignore\").splitlines()\n",
    "        return \"\\n\".join(lines[-max_lines:])\n",
    "    except Exception as e:\n",
    "        return f\"(failed to read server.log: {e})\"\n",
    "\n",
    "for i in range(1800):  # 最多等 3600 秒\n",
    "    try:\n",
    "        h = requests.get(f\"{SERVICE_URL}/health\", timeout=5).json()\n",
    "    except Exception as e:\n",
    "        if i % 5 == 0:\n",
    "            print(f\"{i*2:>4}s\", \"waiting for server...\", repr(e))\n",
    "        if pid_path.exists():\n",
    "            try:\n",
    "                pid = int(pid_path.read_text().strip() or \"0\")\n",
    "            except Exception:\n",
    "                pid = 0\n",
    "            if pid and not pid_alive(pid):\n",
    "                print(\"\\nserver process exited; last logs:\\n\")\n",
    "                print(tail_log())\n",
    "                raise\n",
    "        time.sleep(2)\n",
    "        continue\n",
    "\n",
    "    if h.get(\"status\") == \"ok\":\n",
    "        print(\"HEALTH:\\n\", json.dumps(h, ensure_ascii=False, indent=2))\n",
    "        if not h.get(\"ready\"):\n",
    "            print(\"NOTE: 未预加载模型，将在 ASR/翻译前按需加载。\")\n",
    "        break\n",
    "    if i % 5 == 0:\n",
    "        print(f\"{i*2:>4}s\", h.get(\"phase\"), h.get(\"progress\"), h.get(\"message\"))\n",
    "    if h.get(\"phase\") == \"error\":\n",
    "        raise RuntimeError(h.get(\"error\") or \"模型加载失败，请查看 server.log\")\n",
    "    time.sleep(2)\n",
    "else:\n",
    "    raise TimeoutError(\"等待服务就绪超时：请查看 server.log\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78875b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 7) 下载测试视频（自动使用链接文件名）\n",
    "\n",
    "OUT_PATH = \"\"  # 留空=使用链接里的文件名\n",
    "FORCE = False  # True=总是重新下载\n",
    "\n",
    "import urllib.parse\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except Exception:\n",
    "    tqdm = None\n",
    "\n",
    "def guess_filename(url: str) -> str:\n",
    "    parts = urllib.parse.urlsplit(url)\n",
    "    name = Path(urllib.parse.unquote(parts.path)).name\n",
    "    if not name:\n",
    "        q = urllib.parse.parse_qs(parts.query or \"\")\n",
    "        for key in (\"filename\", \"file\", \"name\"):\n",
    "            if q.get(key):\n",
    "                name = q[key][0]\n",
    "                break\n",
    "    if not name:\n",
    "        name = \"video.mp4\"\n",
    "    return name\n",
    "\n",
    "def normalize_url(url: str) -> str:\n",
    "    parts = urllib.parse.urlsplit(url)\n",
    "    # 对 path 做编码，避免包含中文路径时部分工具报错\n",
    "    path = urllib.parse.quote(parts.path)\n",
    "    return urllib.parse.urlunsplit((parts.scheme, parts.netloc, path, parts.query, parts.fragment))\n",
    "\n",
    "out = Path(OUT_PATH) if OUT_PATH else Path(guess_filename(VIDEO_URL))\n",
    "VIDEO_FILE = str(out)  # 给后续单元格使用\n",
    "print(\"save as:\", out)\n",
    "if out.exists() and out.stat().st_size > 0 and not FORCE:\n",
    "    print(\"exists:\", out, out.stat().st_size)\n",
    "else:\n",
    "    url = normalize_url(VIDEO_URL)\n",
    "    with requests.get(url, stream=True, timeout=60) as r:\n",
    "        r.raise_for_status()\n",
    "        total = int(r.headers.get(\"content-length\") or 0)\n",
    "        if tqdm and total > 0:\n",
    "            pbar = tqdm(total=total, unit=\"B\", unit_scale=True, desc=\"download\")\n",
    "        else:\n",
    "            pbar = None\n",
    "        with open(out, \"wb\") as f:\n",
    "            for chunk in r.iter_content(chunk_size=1024 * 1024):\n",
    "                if not chunk:\n",
    "                    continue\n",
    "                f.write(chunk)\n",
    "                if pbar:\n",
    "                    pbar.update(len(chunk))\n",
    "        if pbar:\n",
    "            pbar.close()\n",
    "    print(\"downloaded:\", out, out.stat().st_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a651e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 8) 翻译生成中文字幕（不润色）\n",
    "from pathlib import Path\n",
    "\n",
    "TARGET_LANG = \"zh\"\n",
    "VIDEO_PATH = Path(globals().get(\"VIDEO_FILE\", \"1.mp4\"))\n",
    "print(\"video:\", VIDEO_PATH)\n",
    "\n",
    "!python batch_translate.py \"{VIDEO_PATH}\" -t {TARGET_LANG} --translation-only --subtitle-format ass\n",
    "\n",
    "SUB_PATH = VIDEO_PATH.with_name(f\"{VIDEO_PATH.stem}_{TARGET_LANG}.ass\")\n",
    "globals()[\"TARGET_LANG\"] = TARGET_LANG\n",
    "globals()[\"SUBTITLE_FILE\"] = str(SUB_PATH)\n",
    "print(\"subtitle:\", SUB_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b820f39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 9) 合并字幕与视频（生成带字幕视频）\n",
    "import json\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "VIDEO_PATH = Path(globals().get(\"VIDEO_FILE\", \"1.mp4\"))\n",
    "TARGET_LANG = globals().get(\"TARGET_LANG\", \"zh\")\n",
    "\n",
    "SUB_PATH = Path(globals().get(\"SUBTITLE_FILE\") or VIDEO_PATH.with_name(f\"{VIDEO_PATH.stem}_{TARGET_LANG}.ass\"))\n",
    "SUB_EXT = SUB_PATH.suffix.lower()\n",
    "BASE_STEM = f\"{VIDEO_PATH.stem}_{TARGET_LANG}\"\n",
    "\n",
    "# soft：内封字幕（不转码，大小≈原视频；字幕清晰，推荐）\n",
    "#   - ASS 内封：MP4 不支持内封 ASS，因此会输出 MKV\n",
    "# hard：硬字幕烧录（需要重编码；ASS 样式生效；编码质量决定清晰度/体积）\n",
    "MODE = \"soft\"  # soft / hard\n",
    "\n",
    "if not VIDEO_PATH.exists():\n",
    "    raise FileNotFoundError(VIDEO_PATH)\n",
    "if not SUB_PATH.exists():\n",
    "    raise FileNotFoundError(SUB_PATH)\n",
    "\n",
    "def ffprobe_json(path: Path) -> dict:\n",
    "    out = subprocess.check_output(\n",
    "        [\n",
    "            \"ffprobe\",\n",
    "            \"-v\",\n",
    "            \"error\",\n",
    "            \"-show_entries\",\n",
    "            \"format=duration,size,bit_rate\",\n",
    "            \"-show_entries\",\n",
    "            \"stream=codec_type,codec_name,width,height,bit_rate\",\n",
    "            \"-of\",\n",
    "            \"json\",\n",
    "            str(path),\n",
    "        ],\n",
    "        text=True,\n",
    "    )\n",
    "    return json.loads(out)\n",
    "\n",
    "cmd_nvenc = None\n",
    "cmd_x264 = None\n",
    "\n",
    "if MODE == \"soft\":\n",
    "    # 内封字幕：不重编码，文件大小基本不变（推荐）\n",
    "    if SUB_EXT == \".ass\":\n",
    "        OUT_PATH = VIDEO_PATH.with_name(f\"{BASE_STEM}.mkv\")\n",
    "        cmd = [\n",
    "            \"ffmpeg\",\n",
    "            \"-y\",\n",
    "            \"-i\",\n",
    "            str(VIDEO_PATH),\n",
    "            \"-i\",\n",
    "            str(SUB_PATH),\n",
    "            \"-map\",\n",
    "            \"0:v\",\n",
    "            \"-map\",\n",
    "            \"0:a?\",\n",
    "            \"-map\",\n",
    "            \"1:0\",\n",
    "            \"-c:v\",\n",
    "            \"copy\",\n",
    "            \"-c:a\",\n",
    "            \"copy\",\n",
    "            \"-c:s\",\n",
    "            \"ass\",\n",
    "            \"-metadata:s:s:0\",\n",
    "            \"language=chi\",\n",
    "            \"-metadata:s:s:0\",\n",
    "            \"title=Chinese\",\n",
    "            \"-disposition:s:0\",\n",
    "            \"default\",\n",
    "            str(OUT_PATH),\n",
    "        ]\n",
    "    else:\n",
    "        OUT_PATH = VIDEO_PATH.with_name(f\"{BASE_STEM}{VIDEO_PATH.suffix or '.mp4'}\")\n",
    "        cmd = [\n",
    "            \"ffmpeg\",\n",
    "            \"-y\",\n",
    "            \"-i\",\n",
    "            str(VIDEO_PATH),\n",
    "            \"-i\",\n",
    "            str(SUB_PATH),\n",
    "            \"-map\",\n",
    "            \"0:v\",\n",
    "            \"-map\",\n",
    "            \"0:a?\",\n",
    "            \"-map\",\n",
    "            \"1:0\",\n",
    "            \"-c:v\",\n",
    "            \"copy\",\n",
    "            \"-c:a\",\n",
    "            \"copy\",\n",
    "            \"-c:s\",\n",
    "            \"mov_text\",\n",
    "            \"-metadata:s:s:0\",\n",
    "            \"language=chi\",\n",
    "            \"-metadata:s:s:0\",\n",
    "            \"title=Chinese\",\n",
    "            \"-disposition:s:0\",\n",
    "            \"default\",\n",
    "            \"-movflags\",\n",
    "            \"+faststart\",\n",
    "            str(OUT_PATH),\n",
    "        ]\n",
    "else:\n",
    "    OUT_PATH = VIDEO_PATH.with_name(f\"{BASE_STEM}{VIDEO_PATH.suffix or '.mp4'}\")\n",
    "    # 硬字幕：会重编码；为了让体积接近原视频，按原视频码率做 ABR（并略加一点给字幕边缘）\n",
    "    info = ffprobe_json(VIDEO_PATH)\n",
    "    height = None\n",
    "    v_bitrate = None\n",
    "    for st in info.get(\"streams\", []) or []:\n",
    "        if st.get(\"codec_type\") == \"video\":\n",
    "            height = st.get(\"height\")\n",
    "            try:\n",
    "                v_bitrate = int(st.get(\"bit_rate\")) if st.get(\"bit_rate\") else None\n",
    "            except Exception:\n",
    "                v_bitrate = None\n",
    "            break\n",
    "    try:\n",
    "        duration = float((info.get(\"format\", {}) or {}).get(\"duration\") or 0)\n",
    "    except Exception:\n",
    "        duration = 0.0\n",
    "    try:\n",
    "        size = int((info.get(\"format\", {}) or {}).get(\"size\") or 0)\n",
    "    except Exception:\n",
    "        size = 0\n",
    "    if not v_bitrate and duration > 0 and size > 0:\n",
    "        v_bitrate = int(size * 8 / duration)  # 退化估算（包含音频，足够用来控体积）\n",
    "    target_k = int((v_bitrate or 800_000) / 1000 * 1.05)  # 轻微余量\n",
    "\n",
    "    if SUB_EXT == \".ass\":\n",
    "        # ASS 直接走 libass（样式以 ASS 为准）\n",
    "        vf = f\"ass={SUB_PATH.as_posix()}:fontsdir=/usr/share/fonts\"\n",
    "    else:\n",
    "        if not height:\n",
    "            height = 720\n",
    "        font_size = min(60, max(24, int(height * 0.06)))\n",
    "        outline = max(2, int(font_size / 16))\n",
    "        margin_v = max(20, int(font_size * 1.2))\n",
    "\n",
    "        style = (\n",
    "            f\"FontName=Noto Sans CJK SC,\"\n",
    "            f\"FontSize={font_size},Bold=1,\"\n",
    "            f\"Outline={outline},Shadow=0,\"\n",
    "            f\"MarginV={margin_v},Alignment=2\"\n",
    "        )\n",
    "        vf = f\"subtitles={SUB_PATH.as_posix()}:charenc=UTF-8:fontsdir=/usr/share/fonts:force_style='{style}'\"\n",
    "\n",
    "    encoders = subprocess.check_output(\n",
    "        [\"ffmpeg\", \"-hide_banner\", \"-encoders\"],\n",
    "        text=True,\n",
    "        stderr=subprocess.STDOUT,\n",
    "    )\n",
    "    use_nvenc = \"h264_nvenc\" in encoders\n",
    "\n",
    "    cmd = [\n",
    "        \"ffmpeg\",\n",
    "        \"-y\",\n",
    "        \"-i\",\n",
    "        str(VIDEO_PATH),\n",
    "        \"-vf\",\n",
    "        vf,\n",
    "        \"-c:a\",\n",
    "        \"copy\",\n",
    "        \"-movflags\",\n",
    "        \"+faststart\",\n",
    "    ]\n",
    "    cmd_nvenc = None\n",
    "    cmd_x264 = None\n",
    "    if use_nvenc:\n",
    "        # 注意：部分环境虽然编译了 nvenc，但运行时可能不可用（驱动/权限），因此下面会自动回退到 libx264。\n",
    "        cmd_nvenc = cmd + [\n",
    "            \"-c:v\",\n",
    "            \"h264_nvenc\",\n",
    "            \"-preset\",\n",
    "            \"p7\",\n",
    "            \"-rc\",\n",
    "            \"vbr\",  # 比 vbr_hq 兼容性更好\n",
    "            \"-b:v\",\n",
    "            f\"{target_k}k\",\n",
    "            \"-maxrate\",\n",
    "            f\"{int(target_k * 1.5)}k\",\n",
    "            \"-bufsize\",\n",
    "            f\"{int(target_k * 2)}k\",\n",
    "            \"-pix_fmt\",\n",
    "            \"yuv420p\",\n",
    "            str(OUT_PATH),\n",
    "        ]\n",
    "\n",
    "    cmd_x264 = cmd + [\n",
    "        \"-c:v\",\n",
    "        \"libx264\",\n",
    "        \"-preset\",\n",
    "        \"slow\",\n",
    "        \"-b:v\",\n",
    "        f\"{target_k}k\",\n",
    "        \"-maxrate\",\n",
    "        f\"{int(target_k * 1.5)}k\",\n",
    "        \"-bufsize\",\n",
    "        f\"{int(target_k * 2)}k\",\n",
    "        \"-pix_fmt\",\n",
    "        \"yuv420p\",\n",
    "        str(OUT_PATH),\n",
    "    ]\n",
    "\n",
    "    cmd = cmd_nvenc or cmd_x264\n",
    "\n",
    "print(\"Running:\\n \", \" \".join(cmd))\n",
    "try:\n",
    "    subprocess.run(cmd, check=True)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    if MODE == \"hard\" and cmd_nvenc is not None:\n",
    "        print(\"\\nNVENC 合并失败，自动回退到 libx264 重试...\\n\")\n",
    "        cmd = cmd_x264\n",
    "        print(\"Running:\\n \", \" \".join(cmd))\n",
    "        subprocess.run(cmd, check=True)\n",
    "    else:\n",
    "        raise\n",
    "globals()[\"SUBBED_FILE\"] = str(OUT_PATH)\n",
    "globals()[\"SUBTITLE_FILE\"] = str(SUB_PATH)\n",
    "print(\"OK video:\", OUT_PATH)\n",
    "print(\"OK subtitle:\", SUB_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ffee10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 10) 复制最终视频+字幕到目录\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# 复制目标目录（可改）\n",
    "EXPORT_DIR = Path(\"/content/drive/MyDrive/share\")\n",
    "EXPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "video = Path(globals().get(\"SUBBED_FILE\", \"\"))\n",
    "sub = Path(globals().get(\"SUBTITLE_FILE\", \"\"))\n",
    "\n",
    "if not video.exists():\n",
    "    raise FileNotFoundError(video)\n",
    "if not sub.exists():\n",
    "    raise FileNotFoundError(sub)\n",
    "\n",
    "# 让字幕和视频同名（仅扩展名不同）\n",
    "sub_ext = (sub.suffix or \".ass\").lower()\n",
    "aligned_sub = video.with_suffix(sub_ext)\n",
    "if aligned_sub != sub:\n",
    "    shutil.copy2(sub, aligned_sub)\n",
    "    sub = aligned_sub\n",
    "\n",
    "dst_video = EXPORT_DIR / video.name\n",
    "dst_sub = EXPORT_DIR / f\"{dst_video.stem}{sub_ext}\"\n",
    "shutil.copy2(video, dst_video)\n",
    "shutil.copy2(sub, dst_sub)\n",
    "\n",
    "globals()[\"SUBBED_FILE\"] = str(dst_video)\n",
    "globals()[\"SUBTITLE_FILE\"] = str(dst_sub)\n",
    "print(\"copied video:\", dst_video)\n",
    "print(\"copied subtitle:\", dst_sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be1c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title （备用）上传到 OpenList/AList（可选） + 下载文件\n",
    "import json\n",
    "from pathlib import Path\n",
    "from urllib.parse import quote\n",
    "from google.colab import userdata\n",
    "\n",
    "import requests\n",
    "\n",
    "# ====== 本地文件（由前面步骤生成）======\n",
    "VIDEO_PATH = Path(globals().get(\"VIDEO_FILE\", \"1.mp4\"))\n",
    "TARGET_LANG = globals().get(\"TARGET_LANG\", \"zh\")\n",
    "SUB_FILE = Path(globals().get(\"SUBTITLE_FILE\") or VIDEO_PATH.with_name(f\"{VIDEO_PATH.stem}_{TARGET_LANG}.ass\"))\n",
    "LOCAL_FILE = Path(globals().get(\"SUBBED_FILE\") or VIDEO_PATH.with_name(f\"{VIDEO_PATH.stem}_{TARGET_LANG}{VIDEO_PATH.suffix or '.mp4'}\"))\n",
    "UPLOAD_FILE_OVERRIDE = \"\"  # 例如 /content/llama_wheels/llama_cpp_python-*.whl\n",
    "if UPLOAD_FILE_OVERRIDE:\n",
    "    import glob\n",
    "    matches = glob.glob(UPLOAD_FILE_OVERRIDE)\n",
    "    LOCAL_FILE = Path(matches[0]) if matches else Path(UPLOAD_FILE_OVERRIDE)\n",
    "print(\"local subtitle:\", SUB_FILE)\n",
    "print(\"local video:\", LOCAL_FILE)\n",
    "\n",
    "# ====== OpenList/AList 上传配置（Colab Secrets/userdata）======\n",
    "UPLOAD_TO_OPENLIST = True  # True=上传；False=跳过\n",
    "OPENLIST_BASE_URL = userdata.get('OPENLIST_BASE_URL')  # 例如 https://oplist.example.com\n",
    "OPENLIST_USERNAME = userdata.get('OPENLIST_USERNAME')\n",
    "OPENLIST_PASSWORD = userdata.get('OPENLIST_PASSWORD')\n",
    "REMOTE_DIR = userdata.get('REMOTE_DIR')  # 例如 /tianyi/test3\n",
    "REMOTE_FILENAME = LOCAL_FILE.name  # 或写死：\"xxx.mp4\"\n",
    "VERIFY_TLS = True  # https 自签证书可设 False\n",
    "\n",
    "def alist_login(base_url: str, username: str, password: str) -> str:\n",
    "    url = f\"{base_url}/api/auth/login\"\n",
    "    # 兼容不同参数名：先按博客（Username/Password），失败再试小写\n",
    "    last = None\n",
    "    for payload in (\n",
    "        {\"Username\": username, \"Password\": password},\n",
    "        {\"username\": username, \"password\": password},\n",
    "    ):\n",
    "        r = requests.post(url, data=payload, timeout=30, verify=VERIFY_TLS)\n",
    "        r.raise_for_status()\n",
    "        last = r.json()\n",
    "        if last.get(\"code\") == 200 and isinstance(last.get(\"data\"), dict) and last[\"data\"].get(\"token\"):\n",
    "            return last[\"data\"][\"token\"]\n",
    "    raise RuntimeError(f\"login failed: {last}\")\n",
    "\n",
    "def alist_mkdir(base_url: str, token: str, path: str):\n",
    "    url = f\"{base_url}/api/fs/mkdir\"\n",
    "    headers = {\"Authorization\": token}\n",
    "    r = requests.post(url, headers=headers, data={\"path\": path}, timeout=30, verify=VERIFY_TLS)\n",
    "    # 目录已存在时通常返回非200或 code!=200，这里不强制失败\n",
    "    try:\n",
    "        return r.json()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def alist_upload_file(base_url: str, token: str, local_path: Path, remote_dir: str, remote_name: str, as_task: bool = True):\n",
    "    url = f\"{base_url}/api/fs/form\"\n",
    "    remote_dir = remote_dir if str(remote_dir).startswith(\"/\") else \"/\" + str(remote_dir)\n",
    "    remote_path = remote_dir.rstrip(\"/\") + \"/\" + remote_name\n",
    "    file_path_header = quote(remote_path, safe=\"/\")  # URL 编码（保留/）\n",
    "    headers = {\n",
    "        \"Authorization\": token,\n",
    "        \"file-path\": file_path_header,\n",
    "    }\n",
    "    if as_task:\n",
    "        # 让服务端以“任务”方式处理（可避免反代等待远端存储上传导致 504 超时）\n",
    "        headers[\"As-Task\"] = \"true\"\n",
    "\n",
    "    def _do_put(hdrs: dict):\n",
    "        # 用 requests-toolbelt 流式 multipart 上传 + 进度条/速度\n",
    "        import time\n",
    "        from tqdm.auto import tqdm\n",
    "        from requests_toolbelt.multipart.encoder import MultipartEncoder, MultipartEncoderMonitor\n",
    "        with local_path.open(\"rb\") as f:\n",
    "            encoder = MultipartEncoder(fields={\"file\": (remote_name, f, \"application/octet-stream\")})\n",
    "            hdrs2 = dict(hdrs)\n",
    "            hdrs2[\"Content-Type\"] = encoder.content_type\n",
    "            hdrs2[\"Content-Length\"] = str(encoder.len)\n",
    "\n",
    "            bar = tqdm(total=encoder.len, unit=\"B\", unit_scale=True, unit_divisor=1024, desc=\"upload\")\n",
    "            t0 = time.time()\n",
    "            last_t = t0\n",
    "            last_b = 0\n",
    "\n",
    "            def _cb(m: MultipartEncoderMonitor):\n",
    "                nonlocal last_t, last_b\n",
    "                cur = m.bytes_read\n",
    "                if cur > bar.n:\n",
    "                    bar.update(cur - bar.n)\n",
    "                now = time.time()\n",
    "                if now - last_t >= 0.5:\n",
    "                    spd = (cur - last_b) / max(1e-6, (now - last_t))\n",
    "                    bar.set_postfix_str(f\"{spd/1024/1024:.2f} MB/s\")\n",
    "                    last_t = now\n",
    "                    last_b = cur\n",
    "\n",
    "            monitor = MultipartEncoderMonitor(encoder, _cb)\n",
    "            try:\n",
    "                # 读超时设很大：避免上传大文件时本地 read timeout\n",
    "                r = requests.put(url, headers=hdrs2, data=monitor, timeout=(30, 24 * 3600), verify=VERIFY_TLS)\n",
    "            finally:\n",
    "                bar.close()\n",
    "            return r\n",
    "\n",
    "    r = _do_put(headers)\n",
    "    if r.status_code in (401, 403) and not str(headers.get(\"Authorization\", \"\")).lower().startswith(\"bearer \"):\n",
    "        headers2 = dict(headers)\n",
    "        headers2[\"Authorization\"] = f\"Bearer {token}\"\n",
    "        r = _do_put(headers2)\n",
    "\n",
    "    r.raise_for_status()\n",
    "    j = r.json()\n",
    "    if j.get(\"code\") != 200:\n",
    "        raise RuntimeError(f\"upload failed: {j}\")\n",
    "    return j\n",
    "\n",
    "\n",
    "def alist_task_info(base_url: str, token: str, tid: str):\n",
    "    url = f\"{base_url}/api/task/upload/info\"\n",
    "    headers = {\"Authorization\": token}\n",
    "    r = requests.post(url, headers=headers, params={\"tid\": tid}, timeout=30, verify=VERIFY_TLS)\n",
    "    if r.status_code in (401, 403) and not str(headers.get(\"Authorization\", \"\")).lower().startswith(\"bearer \"):\n",
    "        headers2 = dict(headers)\n",
    "        headers2[\"Authorization\"] = f\"Bearer {token}\"\n",
    "        r = requests.post(url, headers=headers2, params={\"tid\": tid}, timeout=30, verify=VERIFY_TLS)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "def wait_upload_task(base_url: str, token: str, tid: str, poll_sec: float = 2.0, timeout_sec: int = 24 * 3600):\n",
    "    import time\n",
    "    from tqdm.auto import tqdm\n",
    "    t0 = time.time()\n",
    "    bar = tqdm(total=100, desc=\"server task\", unit=\"%\")\n",
    "    last_p = 0\n",
    "    try:\n",
    "        while True:\n",
    "            info = alist_task_info(base_url, token, tid)\n",
    "            items = info.get(\"data\") or []\n",
    "            task = items[0] if items else None\n",
    "            if not task:\n",
    "                raise RuntimeError(f\"task not found: {info}\")\n",
    "            state = str(task.get(\"state\") or \"\")\n",
    "            status = str(task.get(\"status\") or \"\")\n",
    "            err = str(task.get(\"error\") or \"\")\n",
    "            try:\n",
    "                p = int(task.get(\"progress\") or 0)\n",
    "            except Exception:\n",
    "                p = 0\n",
    "            p = max(0, min(100, p))\n",
    "            if p > last_p:\n",
    "                bar.update(p - last_p)\n",
    "                last_p = p\n",
    "            if status:\n",
    "                bar.set_postfix_str(status[:60])\n",
    "\n",
    "            if state in (\"succeeded\", \"success\") or p >= 100:\n",
    "                return task\n",
    "            if state in (\"failed\", \"error\"):\n",
    "                raise RuntimeError(f\"upload task failed: {err or task}\")\n",
    "            if time.time() - t0 > timeout_sec:\n",
    "                raise TimeoutError(f\"upload task timeout after {timeout_sec}s: {tid}\")\n",
    "            time.sleep(poll_sec)\n",
    "    finally:\n",
    "        bar.close()\n",
    "\n",
    "if UPLOAD_TO_OPENLIST:\n",
    "    if not OPENLIST_BASE_URL:\n",
    "        raise ValueError(\"OPENLIST_BASE_URL is empty\")\n",
    "    if not OPENLIST_USERNAME or not OPENLIST_PASSWORD:\n",
    "        raise ValueError(\"OPENLIST_USERNAME/OPENLIST_PASSWORD is empty\")\n",
    "    if not LOCAL_FILE.exists():\n",
    "        raise FileNotFoundError(LOCAL_FILE)\n",
    "\n",
    "    print(\"login ...\")\n",
    "    token = alist_login(OPENLIST_BASE_URL, OPENLIST_USERNAME, OPENLIST_PASSWORD)\n",
    "    print(\"token ok\")\n",
    "\n",
    "    if REMOTE_DIR and REMOTE_DIR != \"/\":\n",
    "        print(\"mkdir ...\", REMOTE_DIR)\n",
    "        alist_mkdir(OPENLIST_BASE_URL, token, REMOTE_DIR)\n",
    "\n",
    "    print(\"upload ...\", LOCAL_FILE, \"->\", REMOTE_DIR, REMOTE_FILENAME)\n",
    "    res = alist_upload_file(OPENLIST_BASE_URL, token, LOCAL_FILE, REMOTE_DIR, REMOTE_FILENAME, as_task=True)\n",
    "    print(\"upload response:\", json.dumps(res, ensure_ascii=False))\n",
    "    tid = (((res.get(\"data\") or {}) .get(\"task\") or {}) .get(\"id\")) if isinstance(res, dict) else None\n",
    "    if tid:\n",
    "        print(\"server task id:\", tid)\n",
    "        final_task = wait_upload_task(OPENLIST_BASE_URL, token, tid)\n",
    "        print(\"upload done:\", json.dumps(final_task, ensure_ascii=False))\n",
    "    else:\n",
    "        print(\"upload ok (no task id)\")\n",
    "\n",
    "# ====== 下载到本地（Colab）======\n",
    "# from google.colab import files\n",
    "\n",
    "# files.download(str(SUB_FILE))\n",
    "# files.download(str(LOCAL_FILE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46694e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title （备用）停止服务\n",
    "import os\n",
    "import signal\n",
    "import pathlib\n",
    "\n",
    "pid_path = pathlib.Path(\"server.pid\")\n",
    "if pid_path.exists():\n",
    "    pid = int(pid_path.read_text().strip())\n",
    "    os.kill(pid, signal.SIGTERM)\n",
    "    print(\"killed:\", pid)\n",
    "else:\n",
    "    print(\"server.pid not found\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}